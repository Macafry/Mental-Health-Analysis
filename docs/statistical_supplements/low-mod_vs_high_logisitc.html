<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.549">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Ian McFarlane">

<title>Anxiety in Context - Predicting Low / Moderate vs High Anxiety</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link href="../site_libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet">
<script src="../site_libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>
<link href="../site_libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet">
<script src="../site_libs/datatables-binding-0.33/datatables.js"></script>
<script src="../site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<link href="../site_libs/dt-core-1.13.6/css/jquery.dataTables.min.css" rel="stylesheet">
<link href="../site_libs/dt-core-1.13.6/css/jquery.dataTables.extra.css" rel="stylesheet">
<script src="../site_libs/dt-core-1.13.6/js/jquery.dataTables.min.js"></script>
<link href="../site_libs/crosstalk-1.2.1/css/crosstalk.min.css" rel="stylesheet">
<script src="../site_libs/crosstalk-1.2.1/js/crosstalk.min.js"></script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Anxiety in Context</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Overview</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-statistical-supplements" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Statistical Supplements</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-statistical-supplements">    
        <li>
    <a class="dropdown-item" href="../statistical_supplements/exploratory_data_analysis.html">
 <span class="dropdown-text">Exploratory Data Analysis</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../statistical_supplements/low-mod_vs_high_logisitc.html">
 <span class="dropdown-text">Low vs.&nbsp;High Anxiety (Logistic)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../statistical_supplements/low_to_moderate_regression.html">
 <span class="dropdown-text">Low–Moderate Anxiety (Linear)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../statistical_supplements/high_anxiety.html">
 <span class="dropdown-text">High Anxiety Model</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../reflection.html"> 
<span class="menu-text">Reflection</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="99">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#model-selection" id="toc-model-selection" class="nav-link" data-scroll-target="#model-selection">Model Selection</a>
  <ul class="collapse">
  <li><a href="#parsimonious-importance-driven-model" id="toc-parsimonious-importance-driven-model" class="nav-link" data-scroll-target="#parsimonious-importance-driven-model">Parsimonious, Importance-Driven Model</a></li>
  <li><a href="#selecting-a-model" id="toc-selecting-a-model" class="nav-link" data-scroll-target="#selecting-a-model">Selecting a Model</a></li>
  </ul></li>
  <li><a href="#diagnostics" id="toc-diagnostics" class="nav-link" data-scroll-target="#diagnostics">Diagnostics</a>
  <ul class="collapse">
  <li><a href="#outlier-detection" id="toc-outlier-detection" class="nav-link" data-scroll-target="#outlier-detection">Outlier Detection</a></li>
  <li><a href="#linearity" id="toc-linearity" class="nav-link" data-scroll-target="#linearity">Linearity</a></li>
  <li><a href="#additivity" id="toc-additivity" class="nav-link" data-scroll-target="#additivity">Additivity</a></li>
  <li><a href="#no-multicollinearity" id="toc-no-multicollinearity" class="nav-link" data-scroll-target="#no-multicollinearity">No Multicollinearity</a></li>
  <li><a href="#model-calibration" id="toc-model-calibration" class="nav-link" data-scroll-target="#model-calibration">Model Calibration</a></li>
  <li><a href="#final-model-summary" id="toc-final-model-summary" class="nav-link" data-scroll-target="#final-model-summary">Final Model Summary</a></li>
  </ul></li>
  <li><a href="#interpreting-the-final-model" id="toc-interpreting-the-final-model" class="nav-link" data-scroll-target="#interpreting-the-final-model">Interpreting the Final Model</a>
  <ul class="collapse">
  <li><a href="#predictor-effects" id="toc-predictor-effects" class="nav-link" data-scroll-target="#predictor-effects">Predictor Effects</a></li>
  <li><a href="#probability-perspective" id="toc-probability-perspective" class="nav-link" data-scroll-target="#probability-perspective">Probability Perspective</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Predicting Low / Moderate vs High Anxiety</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Ian McFarlane </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<section id="overview" class="level2">
<h2 class="anchored" data-anchor-id="overview">Overview</h2>
<p>As our primary modeling goal is <strong>interpretation</strong>, logistic regression is a natural choice. It offers a balance between statistical rigor and interpretability, allowing us to quantify the direction and strength of associations between predictors and the probability of high anxiety.</p>
<p>Our exploratory data analysis revealed distinct behavioral patterns between the two outcome groups — <em>Low/Moderate Anxiety</em> vs <em>High Anxiety</em> — suggesting that a logistic regression model should be capable of capturing meaningful signal from the predictors.</p>
<p>Before fitting the model, we assessed the distribution of the binary outcome. The result indicated a <strong>substantial class imbalance</strong>, with approximately a 10:1 ratio favoring the <em>Low/Moderate Anxiety</em> group. Despite this, the minority class (<em>High Anxiety</em>) includes over 1,000 observations — a sufficient sample size for modeling, especially given our focus on estimation rather than classification performance.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>
Low/Moderate Anxiety         High Anxiety 
                9986                 1014 </code></pre>
</div>
</div>
<p>While class imbalance often warrants consideration of remedies such as class weighting or resampling (e.g., SMOTE, undersampling), these approaches come with notable trade-offs. Weighted models complicate coefficient interpretation by altering the meaning of the estimated log-odds, while resampling distorts the natural prevalence of the outcome — a key feature when the goal is to understand real-world data as it is, not as it might be under synthetic balance.</p>
<p>Because our objective is to <strong>understand the relationship between predictors and the likelihood of high anxiety</strong> in the real population, we deliberately avoid rebalancing techniques. Instead, we proceed with a standard logistic regression model, relying on its capacity to yield interpretable and statistically sound insights, even in the presence of imbalance.</p>
</section>
<section id="model-selection" class="level2">
<h2 class="anchored" data-anchor-id="model-selection">Model Selection</h2>
<section id="parsimonious-importance-driven-model" class="level3">
<h3 class="anchored" data-anchor-id="parsimonious-importance-driven-model">Parsimonious, Importance-Driven Model</h3>
<p>We computed permutation-based feature importance using a random forest. A clear inflection point in the importance rankings suggests that the top five variables—Therapy Sessions, Stress Level, Sleep Hours, Caffeine Intake, and Diet Quality—form a distinct group, contributing substantially more predictive information than the remaining features. This observation, paired with the common rule-of-thumb of limiting logistic models to ~5 predictors to avoid overfitting, motivated our choice to begin with this compact set.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="low-mod_vs_high_logisitc_files/figure-html/feature_importance-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>While additional variables may be considered later, this starting point balances statistical rigor, model stability, and interpretability. All subsequent decisions are guided by model comparison statistics and the overarching goal of building a transparent and communicable model.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>AnxietyBinary ~ Therapy.Sessions + Stress.Level + Sleep.Hours + 
    Caffeine.Intake + Diet.Quality</code></pre>
</div>
</div>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true">Removing Variables</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" role="tab" aria-controls="tabset-1-2" aria-selected="false">Adding Variables</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-3" role="tab" aria-controls="tabset-1-3" aria-selected="false">Step-wise Selection</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<p>To test whether each predictor in the initial model contributes meaningfully to model fit, we conducted a series of single-variable removal tests. For each test, a simplified model was created by dropping one predictor, then compared to the five-variable model using AIC, BIC, and Bayes Factors. This approach helps identify variables that may be redundant or contribute minimal added value relative to the model’s complexity.</p>
<p>The results (shown below) indicate that removing any one of the five predictors leads to a notably worse-fitting model across all criteria. In each case, BIC increases and the corresponding Bayes Factor favors the full model, suggesting that each variable provides unique explanatory signal. These findings support retaining all five predictors in the base model.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Therapy Sessions:</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                      aic      bic  bayes.factor      p
simplified_model 1155.404 1191.933  0.000000e+00 &lt;2e-16
initial_model     581.382  625.216 1.150797e+123       </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Stress Level:</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                     aic     bic bayes.factor      p
simplified_model 824.232 860.760 0.000000e+00 &lt;2e-16
initial_model    581.382 625.216 1.405521e+51       </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Sleep Hours:</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                      aic      bic  bayes.factor      p
simplified_model 1287.966 1324.494  0.000000e+00 &lt;2e-16
initial_model     581.382  625.216 7.019365e+151       </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Caffeine Intake:</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                     aic     bic bayes.factor      p
simplified_model 720.781 757.309 0.000000e+00 &lt;2e-16
initial_model    581.382 625.216 4.826904e+28       </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Diet Quality:</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                     aic     bic bayes.factor      p
simplified_model 704.694 741.222 0.000000e+00 &lt;2e-16
initial_model    581.382 625.216 1.550702e+25       </code></pre>
</div>
</div>
</div>
<div id="tabset-1-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-2-tab">
<p>We next tested whether additional predictors, ranked by permutation importance, meaningfully improved model fit. Each was tentatively added in sequence, with comparisons based on AIC, BIC, and Bayes Factors.</p>
<p>Heart Rate, Sweating Level, Breathing Rate, Physical Activity, and Age all improved fit and were retained. Alcohol Consumption did not—BIC increased, and the Bayes Factor favored the simpler model—so no further variables were added.</p>
<p>The resulting model includes all predictors supported by importance rankings and model comparison statistics, without incorporating variables of negligible value.</p>
<section id="heart-rate" class="level5">
<h5 class="anchored" data-anchor-id="heart-rate">Heart Rate</h5>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>                     aic     bic bayes.factor      p
no_heart_rate    581.382 625.216            0 &lt;2e-16
heart_rate_added 536.020 587.160    183547794       </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                     aic    bic bayes.factor      p
heart_rate_added 536.020 587.16            0 &lt;2e-16
sweating_added   492.385 550.83     77427673       </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                    aic     bic bayes.factor      p
sweating_added  492.385 550.830        0.008 &lt;2e-16
breathing_added 475.327 541.078      131.140       </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                    aic     bic bayes.factor      p
breathing_added 475.327 541.078 0.000000e+00 &lt;2e-16
activity_added  381.729 454.786 5.470769e+18       </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                   aic     bic bayes.factor      p
activity_added 381.729 454.786        0.006 &lt;2e-16
age_added      364.269 444.631      160.329       </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                  aic     bic bayes.factor     p
age_added     364.269 444.631       31.559 0.121
alcohol_added 363.867 451.535        0.032      </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>AnxietyBinary ~ Therapy.Sessions + Stress.Level + Sleep.Hours + 
    Caffeine.Intake + Diet.Quality + Heart.Rate + Sweating.Level + 
    Breathing.Rate + Physical.Activity + Age</code></pre>
</div>
</div>
</section>
</div>
<div id="tabset-1-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-3-tab">
<p>To compare our manual approach against a traditional model selection method, we ran a stepwise selection procedure using AIC. The process began with the initial five-variable model and evaluated additions and removals based on AIC improvements.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>AnxietyBinary ~ Therapy.Sessions + Stress.Level + Sleep.Hours + 
    Caffeine.Intake + Diet.Quality + Physical.Activity + Sweating.Level + 
    Heart.Rate + Age + Breathing.Rate + Alcohol.Consumption</code></pre>
</div>
</div>
<p>The stepwise procedure yielded a model nearly identical to the one selected manually—differing only by the inclusion of <code>Alcohol Consumption</code>, which our manual process excluded due to weaker model comparison support. This convergence supports the robustness of the manually selected model.</p>
</div>
</div>
</div>
</section>
<section id="selecting-a-model" class="level3">
<h3 class="anchored" data-anchor-id="selecting-a-model">Selecting a Model</h3>
<p>To compare candidate models, we evaluated their discriminative performance using the Area Under the ROC Curve (AUC). AUC offers a single, interpretable measure of how well a model distinguishes between high and low/moderate anxiety cases, and is a pragmatic way to navigate <strong>model decision overload</strong> when all candidates appear strong. In our analysis, every model — from the initial five-variable additive model to the fully extended version — achieved AUCs exceeding 0.998.</p>
<p>This uniformly high performance presented a practical dilemma: <strong>when every model performs exceptionally, how do we choose?</strong></p>
<div class="cell">
<div class="cell-output-display">
<div class="datatables html-widget html-fill-item" id="htmlwidget-ca896ae370120fd139ae" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-ca896ae370120fd139ae">{"x":{"filter":"none","vertical":false,"data":[["1","2","3","4","5"],["importance (5 variables)","importance (5 variables) + Heart Rate","Fully Fxtended Importance","Step-wise Selection","Full Model (All varibles)"],[0.998,0.9981,0.9988,0.9988,0.9989]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>Model<\/th>\n      <th>AUC<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"className":"dt-right","targets":2},{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"Model","targets":1},{"name":"AUC","targets":2}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
</div>
</div>
<p>While AUC differences were numerically small (e.g., +0.0005 from importance-based five-variable model to full model with all variables), they underscore a broader tradeoff. The models offering slight performance gains did so at the cost of complexity and interpretability. AUC does not reflect:</p>
<ul>
<li><p>Calibration — whether predicted probabilities match actual outcomes.</p></li>
<li><p>Local fit — whether the model performs equally well across different subgroups.</p></li>
<li><p>Explanatory clarity — whether stakeholders can make sense of the results.</p></li>
</ul>
<p>We used AUC as a pragmatic filter, not a final arbiter. Its role was to flag when a model’s added complexity didn’t meaningfully improve performance, so we could focus on models that were both accurate and communicable. As such, we <strong>selected the importance-guided five-variable model</strong> for its balance of clarity and explanatory power — simple enough to interpret easily, yet robust enough to capture the key signals in the data.</p>
</section>
</section>
<section id="diagnostics" class="level2">
<h2 class="anchored" data-anchor-id="diagnostics">Diagnostics</h2>
<p>With our model selected, we now assess its diagnostics to ensure the assumptions of logistic regression are reasonably satisfied and that the results are stable and interpretable. This section is organized around three core pillars of diagnostic evaluation:</p>
<ul>
<li><strong>Outlier analysis</strong>, which helps identify individual observations that may unduly influence model estimates or mask broader patterns.</li>
<li><strong>Structural assumption checks</strong>, including linearity, additivity (no interaction terms), and multicollinearity, which apply on the logit scale and ensure the model’s functional form remains appropriate.</li>
<li><strong>Calibration assessment</strong>, which verifies that predicted probabilities align with observed outcome frequencies and that the model performs as a reliable estimator.</li>
</ul>
<section id="outlier-detection" class="level3">
<h3 class="anchored" data-anchor-id="outlier-detection">Outlier Detection</h3>
<p>Given the large sample size (~11,000 observations), the presence of outliers is statistically expected. However, certain outliers can have a disproportionate impact on model interpretation and parameter estimates.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" role="tab" aria-controls="tabset-2-1" aria-selected="true">Plots</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" role="tab" aria-controls="tabset-2-2" aria-selected="false">Systematic Outlier Selection</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-3" role="tab" aria-controls="tabset-2-3" aria-selected="false">Modeling Trimmed vs.&nbsp;Full Dataset</a></li></ul>
<div class="tab-content">
<div id="tabset-2-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-2-1-tab">
<p>To explore this possibility, we generated four diagnostic plots aimed at visually identifying potentially problematic points.</p>
<p>The four plots include:</p>
<ol type="1">
<li><p>Leverage vs.&nbsp;Cook’s Distance — highlights points that are both extreme in predictor space and exert strong global influence.</p></li>
<li><p>Linear Predictor vs.&nbsp;Pearson Residuals — assesses model fit and potential non-linearity across the logit scale.</p></li>
<li><p>Leverage vs.&nbsp;Pearson Residuals — identifies poorly fitted observations that may reside in sparse regions of the predictor space.</p></li>
<li><p>Cook’s Distance by Observation Index — detects globally influential observations without reference to specific predictors.</p></li>
</ol>
<p><em>Note</em>: Labels were added heuristically, prioritizing points with the most extreme values while minimizing overlap to preserve readability. These labels are illustrative and do not represent an exhaustive set of outliers.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="low-mod_vs_high_logisitc_files/figure-html/outlier_plots-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="1344"></p>
</figure>
</div>
</div>
</div>
<p>We highlight two key groups:</p>
<ul>
<li><p><strong>Points 10306, 2112, and 3963</strong> These cases have large Pearson residuals but low leverage—meaning they aren’t unusual in terms of predictor values but are still mispredicted. All were labeled as “Low/Moderate Anxiety” but predicted as “High Anxiety,” likely due to high stress levels (9–10) and low therapy engagement (0–3 sessions/month). These seem like plausible edge cases, not data errors.</p></li>
<li><p><strong>Points 10699, 6037, and 4214</strong> These cases have high leverage and high Cook’s Distance but low residuals—suggesting that, despite being in sparse regions of the predictor space, the model predicted them reasonably well. Their predicted probabilities hover near the decision threshold (0.29 for 6037 and 0.5 for 10699 and 4214), which reflects some model uncertainty and aligns with their unusual combinations of predictors.</p></li>
</ul>
</div>
<div id="tabset-2-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-2-tab">
<p>While manual inspection is helpful, it’s not feasible to review every flagged case. Instead, we systematically selected the top 30 observations using the following criteria:</p>
<ul>
<li><p>Absolute Pearson residual &gt; 2</p></li>
<li><p>Cook’s Distance &gt; 4 / n</p></li>
<li><p>Ranked by Cook’s Distance, prioritizing the most influential cases</p></li>
</ul>
<div class="cell">
<div class="cell-output-display">
<div class="datatables html-widget html-fill-item" id="htmlwidget-a9156579027a871ae7cf" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-a9156579027a871ae7cf">{"x":{"filter":"none","vertical":false,"data":[["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","23","24","25","26","27","28","29","30"],[0,3,1,5,4,5,4,8,5,3,5,2,8,5,7,8,12,4,7,1,9,6,6,9,6,5,3,2,7,4],[9,10,10,10,10,8,10,9,10,9,9,9,6,10,10,10,10,10,10,9,10,6,10,7,10,9,9,9,9,8],[6,7.1,7.2,6.9,6.5,7.4,7.5,4.4,4.1,6.6,3.4,3.9,5.7,5.4,4.8,5.4,7.1,5.4,4.9,5.1,6.3,4.5,6.2,5.3,5.6,6.5,4.1,5.1,6,6.1],[585,351,396,567,261,230,327,320,467,285,394,179,532,565,394,301,197,599,254,590,380,435,518,277,517,324,509,587,376,544],[10,10,5,9,8,3,1,9,10,5,2,5,2,1,2,2,7,2,3,4,7,3,2,5,3,3,6,1,1,4],["High Anxiety","High Anxiety","High Anxiety","High Anxiety","High Anxiety","High Anxiety","High Anxiety","Low/Moderate Anxiety","Low/Moderate Anxiety","High Anxiety","Low/Moderate Anxiety","High Anxiety","Low/Moderate Anxiety","Low/Moderate Anxiety","Low/Moderate Anxiety","Low/Moderate Anxiety","High Anxiety","Low/Moderate Anxiety","Low/Moderate Anxiety","High Anxiety","Low/Moderate Anxiety","Low/Moderate Anxiety","Low/Moderate Anxiety","Low/Moderate Anxiety","Low/Moderate Anxiety","High Anxiety","Low/Moderate Anxiety","Low/Moderate Anxiety","Low/Moderate Anxiety","High Anxiety"],[0.0002163003428063789,6.173930309280208e-05,0.0001453810883178419,0.0149422661235925,0.001003897316478939,0.0005847221624491886,0.007351048844116983,0.8846987697701384,0.8125911091082125,0.0007647884160514348,0.9977598834476833,0.08646440517279619,0.900840495636452,0.9842790800531508,0.9958113897840523,0.9820201549113282,0.4970630675317959,0.9462931203332665,0.9598257363372783,0.1626340974548345,0.6874754429324332,0.831593140622787,0.8886572577066248,0.6928123762752891,0.95555014153193,0.03742145289606677,0.7558461927920643,0.7446284901562936,0.8648964928911396,0.08523951882716131],["Low/Moderate Anxiety","Low/Moderate Anxiety","Low/Moderate Anxiety","Low/Moderate Anxiety","Low/Moderate Anxiety","Low/Moderate Anxiety","Low/Moderate Anxiety","High Anxiety","High Anxiety","Low/Moderate Anxiety","High Anxiety","Low/Moderate Anxiety","High Anxiety","High Anxiety","High Anxiety","High Anxiety","Low/Moderate Anxiety","High Anxiety","High Anxiety","Low/Moderate Anxiety","High Anxiety","High Anxiety","High Anxiety","High Anxiety","High Anxiety","Low/Moderate Anxiety","High Anxiety","High Anxiety","High Anxiety","Low/Moderate Anxiety"],[0.05817069941908526,0.05715962197328631,0.04072024488432451,0.03290672815284083,0.0321088929448643,0.03167852283251673,0.02896264266867106,0.02473386063849154,0.02398111072601009,0.02331003205719237,0.02208697578929886,0.01880622497411396,0.01765476071592987,0.01580031306364591,0.01553350138447564,0.01504428623820878,0.01383126266589937,0.01268959870972716,0.01177434321093216,0.0107662809791504,0.01041362516428552,0.009848826038136296,0.009716766766784823,0.009425103314120376,0.009113620717679806,0.008907018127245222,0.008369432969698888,0.008212912432904002,0.007861799065045083,0.007817407838514459],[67.98677209246088,127.2640475629481,82.93053570177595,8.119375167081765,31.54548800747859,41.34264083906759,11.62045651380281,-2.770006199950444,-2.082288678638273,36.1462471830116,-21.10462849563639,3.250454250682961,-3.014093891109841,-7.912617081175944,-15.41890635591152,-7.390387797930021,1.005891217860986,-4.197569358374732,-4.887899103891908,2.26909058748797,-1.483154933035417,-2.222161202484995,-2.825115379220536,-1.50177877277212,-4.636513720930513,5.071749168224642,-1.75948255211323,-1.707589997772695,-2.530164491919893,3.275919358190595],[7.549898479165313e-05,2.117438196363731e-05,3.552236194279326e-05,0.002977151652609477,0.0001935236173016671,0.0001111791038769849,0.001283593253495355,0.01862728816318166,0.03114957577993149,0.0001070224107222656,0.0002973539865472839,0.0104576365732255,0.011395790159656,0.001509608816993444,0.0003917176684613882,0.001647238293643782,0.07081360880421922,0.004284243398278745,0.002939587706474558,0.01224095557102251,0.02689664379137471,0.0116888552543537,0.007199864213646157,0.02389035772646933,0.00253080153755316,0.002069040756244524,0.01571516498129665,0.01635162781338752,0.007261814180703496,0.004332872932583546],[-8.438626316402051,-9.692528085519431,-8.836006676256883,-4.188506402692032,-6.902861135807463,-7.443788866355407,-4.90553407510838,2.037699116892,1.466935230132749,-7.175146261702146,6.098984752817816,-2.357589512031438,2.206598502762582,4.136917168699761,5.471188883757653,4.000360419245071,-0.01174786498347169,2.869011267134692,3.17352516012589,-1.638758257941564,0.7883430608265503,1.596960473918035,2.077098411932689,0.8133005081198577,3.067925461166221,-3.247371523395281,1.130039522682302,1.070166036815523,1.856568634390142,-2.373197099501818],[2112,10306,3963,2221,60,2906,1820,1326,7681,3629,5441,1407,2615,6565,7962,7529,10699,5558,4084,2760,9721,3731,10247,5313,5657,7456,661,1702,5721,9186]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>Therapy.Sessions<\/th>\n      <th>Stress.Level<\/th>\n      <th>Sleep.Hours<\/th>\n      <th>Caffeine.Intake<\/th>\n      <th>Diet.Quality<\/th>\n      <th>AnxietyBinary<\/th>\n      <th>PredictedProb<\/th>\n      <th>PredictedAnxiety<\/th>\n      <th>Cook<\/th>\n      <th>PearsonResiduals<\/th>\n      <th>Leverage<\/th>\n      <th>LinearPredictors<\/th>\n      <th>Row<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"className":"dt-right","targets":[1,2,3,4,5,7,9,10,11,12,13]},{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"Therapy.Sessions","targets":1},{"name":"Stress.Level","targets":2},{"name":"Sleep.Hours","targets":3},{"name":"Caffeine.Intake","targets":4},{"name":"Diet.Quality","targets":5},{"name":"AnxietyBinary","targets":6},{"name":"PredictedProb","targets":7},{"name":"PredictedAnxiety","targets":8},{"name":"Cook","targets":9},{"name":"PearsonResiduals","targets":10},{"name":"Leverage","targets":11},{"name":"LinearPredictors","targets":12},{"name":"Row","targets":13}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
</div>
</div>
<p>These 30 observations were reviewed for unusual predictor combinations. Some notable patterns included:</p>
<ul>
<li><p>High anxiety despite good diet quality and/or low caffeine intake</p></li>
<li><p>High stress levels paired with low anxiety</p></li>
</ul>
<p>While these combinations are rare, they’re not implausible. Excluding them would risk modeling an oversimplified—and potentially biased—version of reality that ignores meaningful edge cases.</p>
</div>
<div id="tabset-2-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-3-tab">
<p>To evaluate the impact of these outliers, we fit a trimmed model that excludes the top 30 most influential observations identified in the previous step.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>                             Term  Full_Model Trimmed_Model      Ratio
(Intercept)           (Intercept) -1.26910159    0.14336484 -0.1129656
Therapy.Sessions Therapy.Sessions  1.07122435    1.71925991  1.6049485
Stress.Level         Stress.Level  0.86483626    1.15320397  1.3334362
Sleep.Hours           Sleep.Hours -2.59648631   -4.12710413  1.5894958
Caffeine.Intake   Caffeine.Intake  0.01058238    0.01643301  1.5528658
Diet.Quality         Diet.Quality -0.55648236   -0.89431778  1.6070910</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Model trained with Full Data:  0.998  AUC</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Model trained with Trimmed Data:  0.9997 AUC (Trimmed Dataset)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Model trained with Trimmed Data:  0.9979 AUC (Full Dataset)</code></pre>
</div>
</div>
<p>The trimmed model preserves the direction of all coefficients, but their magnitudes increase by roughly 1.5×, consistent with the model being fit on less variable data. In linear regression, this kind of inflation might suggest overfitting or instability. In logistic regression, though, it typically reflects increased confidence in predictions rather than a meaningful gain in accuracy.</p>
<p>In terms of predictive performance, the difference is negligible. The trimmed model performs nearly perfectly on the reduced dataset—but that’s expected and uninformative, since the most influential points were removed. When evaluated on the full dataset—a more honest test—its AUC drops by just 0.0001. This suggests that, while the trimmed model has more extreme coefficients, it doesn’t improve performance and may even generalize slightly worse.</p>
<p>Given our goal of modeling real-world data, we choose to <strong>retain the model trained on the full dataset</strong>. It better captures natural variability and avoids excluding rare but plausible observations that might otherwise be misrepresented or lost.</p>
</div>
</div>
</div>
</section>
<section id="linearity" class="level3">
<h3 class="anchored" data-anchor-id="linearity">Linearity</h3>
<p>The linearity plots show slight “S-shaped” curves for <code>Diet Quality</code>, <code>Caffeine Intake</code>, and <code>Stress Level</code>, suggesting mild nonlinearity near the extremes. These deviations appear subtle and are unlikely to meaningfully affect model performance. In contrast, <code>Therapy Sessions</code> and <code>Sleep Hours</code> show more pronounced curvature at higher log-odds, indicating a clearer violation of the linearity assumption. Interestingly, both exhibit patterns that resemble bimodal behavior, which may suggest that the model is underestimating their effects—possibly due to hidden structure or interaction effects. Rather than applying transformations prematurely, we next examine the additivity assumption to see whether interactions might explain these patterns.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="low-mod_vs_high_logisitc_files/figure-html/linearity-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="1344"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="additivity" class="level3">
<h3 class="anchored" data-anchor-id="additivity">Additivity</h3>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-3-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-1" role="tab" aria-controls="tabset-3-1" aria-selected="true">Identifying 2-way interactions</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-2" role="tab" aria-controls="tabset-3-2" aria-selected="false">Additive vs.&nbsp;Interaction Model</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-3" role="tab" aria-controls="tabset-3-3" aria-selected="false">Interaction Plots</a></li></ul>
<div class="tab-content">
<div id="tabset-3-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-3-1-tab">
<p>To test whether any interaction terms improve model fit, we use a likelihood ratio test comparing the additive model to one with all 2-way interactions. This is preferable to AIC or BIC here, since a few strong interactions could be obscured by others that slightly worsen fit. The LRT directly tests whether <strong>any</strong> interaction term adds value overall.</p>
<p>The likelihood ratio test shows that at least one interaction significantly improves model fit (p &lt; 0.001), suggesting a violation of the additivity assumption and supporting the presence of interaction effects.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Deviance Table

Model 1: AnxietyBinary ~ Sleep.Hours + Therapy.Sessions + Diet.Quality + 
    Stress.Level + Caffeine.Intake
Model 2: AnxietyBinary ~ (Sleep.Hours + Therapy.Sessions + Diet.Quality + 
    Stress.Level + Caffeine.Intake)^2
  Resid. Df Resid. Dev Df Deviance  Pr(&gt;Chi)    
1     10994     569.38                          
2     10984     518.88 10   50.503 2.156e-07 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p>Now that we know interaction terms collectively improve model fit, we use information criteria (AIC, BIC, and Bayes Factors) to identify which specific 2-way interactions are most supported. This shifts our focus from formal testing to model selection, prioritizing parsimony and interpretability.</p>
<div class="cell">
<div class="cell-output-display">
<div class="datatables html-widget html-fill-item" id="htmlwidget-77acb38031dfa5befd80" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-77acb38031dfa5befd80">{"x":{"filter":"none","vertical":false,"data":[["1","5","11","2","7","4","8","3","10","6","9"],["None (Additive Model)","Therapy.Sessions:Diet.Quality","Sleep.Hours:Therapy.Sessions","Sleep.Hours:Diet.Quality","Therapy.Sessions:Caffeine.Intake","Sleep.Hours:Caffeine.Intake","Diet.Quality:Stress.Level","Sleep.Hours:Stress.Level","Stress.Level:Caffeine.Intake","Therapy.Sessions:Stress.Level","Diet.Quality:Caffeine.Intake"],[581.3819999999999,570.707,571.426,576.2329999999999,581.894,582.129,582.784,582.899,583.3339999999999,583.365,583.38],[625.216,621.846,622.566,627.372,633.034,633.269,633.924,634.038,634.473,634.505,634.519],[null,5.391,3.762,0.34,0.02,0.018,0.013,0.012,0.01,0.01,0.01],[null,"&lt;2e-16","0.001","0.008","0.223","0.263","0.44","0.487","0.826","0.897","0.965"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>Interaction<\/th>\n      <th>AIC<\/th>\n      <th>BIC<\/th>\n      <th>BayesFactor<\/th>\n      <th>p_value<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"pageLength":11,"columnDefs":[{"className":"dt-right","targets":[2,3,4]},{"orderable":false,"targets":0},{"name":" ","targets":0},{"name":"Interaction","targets":1},{"name":"AIC","targets":2},{"name":"BIC","targets":3},{"name":"BayesFactor","targets":4},{"name":"p_value","targets":5}],"order":[],"autoWidth":false,"orderClasses":false,"lengthMenu":[10,11,25,50,100]}},"evals":[],"jsHooks":[]}</script>
</div>
</div>
<p>While some interaction models showed moderate Bayes Factors (e.g., BF ≈ 5) and small BIC improvements (ΔBIC &lt; 4), these results should be interpreted with caution given the large sample size (~11,000). At this scale, even minor departures from additivity can appear statistically significant without providing meaningful gains in interpretability or explanatory value.</p>
<p>Still, while each interaction term shows only modest support on its own, their combined effect may be more substantial. Notably, interactions between <code>Therapy Sessions</code> and <code>Diet Quality</code>, <code>Sleep Hours</code> and <code>Therapy Sessions</code>, and <code>Sleep Hours</code> and <code>Diet Quality</code> each showed mild support when tested individually.</p>
<p>The three selected interaction terms form a natural set, suggesting that together they may capture a more coherent structure in the data. To evaluate this, let’s fit a model including all three pairwise interactions.</p>
</div>
<div id="tabset-3-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-2-tab">
<p>The interaction model is statistically superior by several criteria. Compared to the additive model, it improves fit substantially with ΔBIC = 14 and Bayes Factor ≈ 990. This is strong evidence that interaction terms — such as between Sleep Hours and Therapy Sessions, or Diet Quality and Sleep — explain meaningful variance in anxiety risk.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>                      aic     bic bayes.factor      p
additive_model    581.382 625.216        0.001 &lt;2e-16
interaction_model 545.670 611.421      989.776       </code></pre>
</div>
</div>
<p>However, our primary aim is not to build a perfect predictor. Instead, we seek a model that is:</p>
<ul>
<li>Clear enough to communicate results to a broad audience,</li>
<li>Parsimonious enough to remain stable and generalizable, and</li>
<li>Transparent enough to identify key relationships.</li>
</ul>
<p>The additive model is <strong>deliberately oversimplified</strong>. It ignores subtle but real interdependencies between predictors. As a result, it cannot capture context-dependent effects — for instance, how the impact of poor diet might vary depending on sleep quality or therapy engagement.</p>
<p>Despite these limitations, the additive model has advantages:</p>
<ul>
<li>Its structure is straightforward, allowing direct interpretation of individual predictors.</li>
<li>It facilitates communication with stakeholders unfamiliar with nonlinear or interaction-heavy models.</li>
<li>Its predictions are nearly as accurate (AUC 0.9980 vs 0.9985) despite being simpler.</li>
</ul>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Additive model AUC:     0.998 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Interaction model AUC:  0.9985 </code></pre>
</div>
</div>
<p>To address this tradeoff, we retain the additive model for our primary analysis, while:</p>
<ul>
<li>Exploring key interactions in a supplementary section, and</li>
<li>Encouraging future work to consider more complex models where interpretability is not paramount.</li>
</ul>
<p>In short: this model is not a perfect mirror of the data — but it’s a deliberately polished lens, tuned to clarify rather than to capture every nuance.</p>
</div>
<div id="tabset-3-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-3-tab">
<p>Although we ultimately favored the additive model for its simplicity and interpretability, visualizing the interactions still reveals meaningful structure that may inform future research or support domain understanding.</p>
<ol type="1">
<li>Sleep Hours consistently exhibits a negative association with log-odds of high anxiety. This negative slope becomes more pronounced when both Therapy Sessions and Diet Quality are low, suggesting that adequate sleep is especially protective in less supportive therapeutic and nutritional contexts.</li>
</ol>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="low-mod_vs_high_logisitc_files/figure-html/additivity_plots_sleep-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<ol start="2" type="1">
<li>Therapy Sessions typically show a mild positive slope, but this flattens or reverses (to slightly negative) under conditions of high Diet Quality and sufficient Sleep, implying that therapy’s marginal contribution may diminish when other protective factors are present.</li>
</ol>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="low-mod_vs_high_logisitc_files/figure-html/additivity_plots_therapy-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<ol start="3" type="1">
<li>Diet Quality demonstrates context-dependent directionality: its slope is positive when Sleep is high and Therapy is low, but negative when Therapy is high and Sleep is low. This may point to a compensatory dynamic: when sleep or therapy are lacking, diet becomes more predictive, but when both are already sufficient, its marginal effect lessens—or even reverses.</li>
</ol>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="low-mod_vs_high_logisitc_files/figure-html/additivity_plots_diet-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>While these patterns aren’t strong enough to justify including interaction terms for performance, they may reflect underlying compensatory or synergistic effects between lifestyle variables. Visualizing these slopes adds interpretive nuance and may highlight thresholds or diminishing returns that are relevant for clinical or behavioral intervention.</p>
</div>
</div>
</div>
</section>
<section id="no-multicollinearity" class="level3">
<h3 class="anchored" data-anchor-id="no-multicollinearity">No Multicollinearity</h3>
<p>All predictors in the model have Variance Inflation Factors (VIFs) below 1.5—well under the common threshold of 5. This suggests that multicollinearity is not a concern, and that the predictors are sufficiently independent to yield stable, interpretable coefficients.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Variance Inflation Factors:</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Therapy.Sessions     Stress.Level      Sleep.Hours  Caffeine.Intake 
        1.260667         1.087368         1.225833         1.100429 
    Diet.Quality 
        1.089014 </code></pre>
</div>
</div>
</section>
<section id="model-calibration" class="level3">
<h3 class="anchored" data-anchor-id="model-calibration">Model Calibration</h3>
<p>For a logistic regression model to be interpretable, its predicted probabilities must be well-calibrated—that is, a 90% prediction should correspond to the event occurring about 90% of the time. In a well-calibrated model, predicted probabilities closely track observed event rates across the range of predictions.</p>
<p>The following two plots visualize this calibration in complementary ways:</p>
<ol type="1">
<li><p><strong>Fine-Grained Calibration Plot</strong> (<em>200 quantile bins</em>): Predictions are grouped into 200 equally sized bins. The closer each point falls to the diagonal line, the better the alignment between predicted and observed frequencies. Deviations indicate areas of under- or over-confidence.</p></li>
<li><p><strong>Coarse Calibration Plot</strong> (<em>5% fixed bins</em>): Predictions are grouped into 5% intervals. Each point is labeled with its bin size, offering insight into the stability of the observed rates—smaller bins are more sensitive to noise.</p></li>
</ol>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="low-mod_vs_high_logisitc_files/figure-html/calibration_plots-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Overall, the model’s predicted probabilities align closely with observed event rates—most points lie near the diagonal line, suggesting strong calibration. In the fine-grained plot, we see dense clusters near (0, 0) and (1, 1), and fewer points in the middle. This reflects a confident model: most predictions are close to 0 or 1, with few uncertain cases near 0.5. The coarser plot confirms this pattern and adds bin sizes, making it easier to assess the reliability of each point</p>
<p>A few notable patterns emerge:</p>
<ul>
<li><p>Bins with small sample sizes (e.g., 9, 16, 18) show more deviation from the diagonal, likely due to sampling variability.</p></li>
<li><p>Several mid-range points lie slightly above the line, indicating the model tends to underestimate the probability of high anxiety in those regions.</p></li>
<li><p>In the low-probability region near (0, 0), the observed event rate is even lower than predicted, suggesting the model slightly overestimates risk in that range.</p></li>
</ul>
<p>None of these deviations appear especially concerning—overall, the model’s predicted probabilities track observed rates well, supporting good calibration.</p>
</section>
<section id="final-model-summary" class="level3">
<h3 class="anchored" data-anchor-id="final-model-summary">Final Model Summary</h3>
<p>Diagnostic analyses indicate that the final logistic regression model is well-calibrated, interpretable, and robust to influential observations. Residual and outlier assessments revealed a small number of plausible edge cases with minimal impact on model stability. Linearity and additivity assumptions were largely satisfied, and while several interaction terms showed mild support, their inclusion yielded negligible gains in either performance or clarity. Calibration plots confirmed strong agreement between predicted and observed probabilities.</p>
<p>These results confirm that the model is well-suited for explanatory use — offering a stable, interpretable, and empirically justified foundation for communication and insight.</p>
</section>
</section>
<section id="interpreting-the-final-model" class="level2">
<h2 class="anchored" data-anchor-id="interpreting-the-final-model">Interpreting the Final Model</h2>
<section id="predictor-effects" class="level3">
<h3 class="anchored" data-anchor-id="predictor-effects">Predictor Effects</h3>
<p>Now that we’re confident in the quality of our model, let’s take a closer look at the logistic regression equation in terms of log-odds:</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
glm(formula = AnxietyBinary ~ Therapy.Sessions + Stress.Level + 
    Sleep.Hours + Caffeine.Intake + Diet.Quality, family = binomial(), 
    data = model_data)

Coefficients:
                  Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)      -1.269102   1.078253  -1.177    0.239    
Therapy.Sessions  1.071224   0.067108  15.963   &lt;2e-16 ***
Stress.Level      0.864836   0.086795   9.964   &lt;2e-16 ***
Sleep.Hours      -2.596486   0.163356 -15.895   &lt;2e-16 ***
Caffeine.Intake   0.010582   0.001045  10.123   &lt;2e-16 ***
Diet.Quality     -0.556482   0.060275  -9.232   &lt;2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 6766.25  on 10999  degrees of freedom
Residual deviance:  569.38  on 10994  degrees of freedom
AIC: 581.38

Number of Fisher Scoring iterations: 10</code></pre>
</div>
</div>
<p>We can express the model as:</p>
<p><span class="math display">\[
\begin{align*}
\widehat{\log\left[\frac{P(\text{Anxiety} = \text{High Anxiety})}{1 - P(\text{Anxiety} = \text{High Anxiety})}\right]} =\ &amp; -1.269 \\
&amp;+ 1.071\ \cdot\ \text{Therapy Sessions} \\
&amp;+ 0.865\ \cdot\ \text{Stress Level} \\
&amp;- 2.596\ \cdot\ \text{Sleep Hours} \\
&amp;+ 0.0106\ \cdot\ \text{Caffeine Intake} \\
&amp;- 0.556\ \cdot\ \text{Diet Quality}
\end{align*}
\]</span></p>
<p>Let’s break down what each predictor means in terms of odds:</p>
<ul>
<li><p>Each additional therapy session increases the odds by a factor of ×2.92, holding all other variables constant.</p></li>
<li><p>Each additional stress level increases the odds by a factor of ×2.37, holding all other variables constant.</p></li>
<li><p>Each additional hour of sleep decreases the odds by a factor of ×0.075 (or roughly ÷13.4), holding all other variables constant.</p></li>
<li><p>Each extra milligram of caffeine increases the odds slightly (×1.011). But people usually consume caffeine in cups of coffee (≈100 mg), so let’s adjust the scale into cups (100 mg). Then, one extra cup increases the odds by a factor of ×2.88 (holding all other variables constant) — a much more meaningful change.</p></li>
<li><p>Finally, an extra level of Diet Quality decreases the odds by a factor of ×0.573, holding all other variables constant.</p></li>
</ul>
</section>
<section id="probability-perspective" class="level3">
<h3 class="anchored" data-anchor-id="probability-perspective">Probability Perspective</h3>
<p>While interpreting probabilities algebraically becomes more convoluted, we can still express the model in probabilistic form using the logistic (sigmoid) transformation: <span class="math display">\[
\widehat{P(\text{Anxiety} = \text{High Anxiety})} =
\dfrac{1}{1 + e^{-\left(
-1.269
+ 1.071\cdot\text{Therapy Sessions}
+ 0.865\cdot\text{Stress Level}
- 2.596\cdot\text{Sleep Hours}
+ 0.0106\cdot\text{Caffeine Intake}
- 0.556\cdot\text{Diet Quality}
\right)}}
\]</span></p>
<p>This sigmoid structure transforms a linear combination of predictors into a predicted probability between 0 and 1. However, when multiple predictors are involved, interpreting this formula — or visualizing individual effects — becomes substantially more complex. Predicted probabilities depend on the full combination of input values, meaning that visualizations can only capture local, conditional effects, not generalizable insights.</p>
<p>For this reason, we focus on interpreting the odds ratios, which offer a clearer and more direct understanding of each predictor’s influence, independent of arbitrary baselines. These effects — such as a 13-fold decrease in odds for each additional hour of sleep, or a near tripling of odds per extra therapy session — provide a strong and interpretable summary of the model’s core insights.</p>
<p>In summary, while logistic regression does support probabilistic interpretation, odds-based analysis offers the most accessible and robust framing for the purposes of this analysis.</p>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>This analysis set out to understand the factors most strongly associated with high anxiety. Using logistic regression, we developed a model that balances strong statistical performance with interpretive clarity — making it well-suited for transparent reporting and structured analysis of variable relationships.</p>
<p>While more complex models with interaction terms yielded modest improvements in fit, they introduced interpretive overhead. We therefore retained a simpler additive model, allowing for straightforward, stable insights. To enrich this view, we analyzed and visualized key interactions separately — highlighting conditional patterns that inform, but do not complicate, the core structure.</p>
<p>Diagnostic checks confirmed that the model is well-calibrated, resilient to outliers, and broadly stable. Though simplified by design, it offers a clear and defensible account of how behavioral and lifestyle factors relate to anxiety — and where deeper complexity begins to emerge.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>