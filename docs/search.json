[
  {
    "objectID": "statistical_supplements/low_to_moderate_regression.html",
    "href": "statistical_supplements/low_to_moderate_regression.html",
    "title": "Predicting across Low / Moderate Axniety Levels",
    "section": "",
    "text": "Exploratory plots revealed a strong relationship between Anxiety Level and Stress Level, providing early confidence in predictive modeling. However, before proceeding, we must consider the nature of our outcome variable. Anxiety Level is numerical, but ordinal—it has a meaningful order, but not necessarily equal spacing between categories. This complicates model selection, as linear regression assumes a continuous and unbounded outcome, where equal differences between values carry consistent meaning.\nWe consider two main modeling approaches:\n\nLinear regression with rounding, which is easy to interpret but not designed for ordinal data.\nOrdinal logistic regression (also known as the proportional odds model), which more accurately reflects the structure of the outcome but is harder to interpret clearly.\nAlternative ordinal modeling frameworks (e.g., partial proportional odds) were not explored, as they were beyond the scope of this analysis.\n\nAlthough ordinal logistic regression is more appropriate in theory, its interpretation can be opaque—especially for non-technical audiences. Linear regression, while a simplification, provides direct and intuitive estimates, making it better suited to our goals, which prioritize interpretability and transparency over statistical precision.\nThat said, we evaluate both models empirically before committing to one. Our first step is to determine which predictors to include. To guide this selection, we use permutation-based variable importance from a random forest model. The resulting plot highlights Stress Level as the most important feature. A noticeable elbow point in the importance scores—specifically between Family History of Anxiety and Occupation—provides a natural cutoff. Based on this, we include the following predictors: Stress Level, Sleep Hours, Caffeine Intake, Therapy Sessions, and Family History of Anxiety.\n\n\n\n\n\n\n\n\n\n\n\nFirst, we fit the ordinal logistic regression model. The results show a clear pattern: all predictors are directionally consistent with expectations. Stress Level, Caffeine Intake, Therapy Sessions, and Family History of Anxiety are positively associated with higher anxiety levels. In contrast, Sleep Hours has a negative association—more sleep corresponds to lower anxiety.\n\n\nCall:\npolr(formula = ordered(Anxiety.Level) ~ Stress.Level + Sleep.Hours + \n    Caffeine.Intake + Therapy.Sessions + Family.History.of.Anxiety, \n    data = model_data, Hess = TRUE)\n\nCoefficients:\n                                 Value Std. Error t value\nStress.Level                  0.608213  0.0085380  71.236\nSleep.Hours                  -0.421707  0.0177904 -23.704\nCaffeine.Intake               0.002571  0.0001345  19.119\nTherapy.Sessions              0.167046  0.0129053  12.944\nFamily.History.of.AnxietyYes  0.205308  0.0449721   4.565\n\nIntercepts:\n    Value    Std. Error t value \n1|2  -1.6484   0.1351   -12.1995\n2|3   0.0611   0.1328     0.4597\n3|4   1.7495   0.1345    13.0033\n4|5   3.4915   0.1382    25.2554\n5|6   5.3197   0.1436    37.0440\n6|7   7.3847   0.1664    44.3791\n\nResidual Deviance: 27852.94 \nAIC: 27874.94 \n\n\nThe confusion matrix below shows that the model performs modestly but meaningfully better than chance in predicting anxiety levels. The overall accuracy is 38.3%—well above the naïve baseline of predicting the majority class (24.2%). This performance is consistent with the challenges of modeling subjective human responses, where perfect classification is unlikely due to inherent noise and ambiguity.\nEncouragingly, for most predicted classes, the most common true label is the correct one, and 86.4% of predictions fall within one level of the actual value. This indicates that while the model may struggle with fine-grained distinctions, it captures the broader structure of the outcome effectively.\nOne notable limitation is the model’s complete failure to predict Anxiety Level 7—the rarest category, with only 123 cases out of 9,986. This likely reflects both class imbalance and the ordinal model’s tendency to shrink predictions toward the center of the scale. Potential remedies include reweighting, resampling, or alternative modeling strategies that better account for the tails of the distribution.\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    1    2    3    4    5    6    7\n         1  332  205   87   17    1    0    0\n         2  484  661  509  154   22    3    0\n         3  198  682  995  639  187   22    1\n         4   25  193  659 1107  686  158   23\n         5    0   15  156  485  681  385   80\n         6    0    0    1   14   52   48   19\n         7    0    0    0    0    0    0    0\n\nOverall Statistics\n                                          \n               Accuracy : 0.3829          \n                 95% CI : (0.3734, 0.3926)\n    No Information Rate : 0.2419          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.2247          \n                                          \n Mcnemar's Test P-Value : NA              \n\n\n\nCases predicted within one level of the true level: 86.41%\n\n\n\n\nWe formally tested the proportional odds assumption using the Brant test. The omnibus test was significant, indicating that the assumption does not hold strictly. At the individual level, Stress Level, Sleep Hours, and Caffeine Intake also showed statistically significant violations.\nHowever, visual inspection of the empirical cumulative logits for each predictor revealed near-parallel trends across thresholds, broadly consistent with the proportional odds framework. A slight divergence in slope between the Anxiety ≥ 2 and Anxiety ≥ 3 thresholds is visible—particularly for Stress Level—suggesting mild non-proportionality at the lower end of the anxiety scale. Additionally, the slope for Anxiety ≥ 7 behaves somewhat erratically, likely due to extreme class imbalance at the highest anxiety level.\nTaken together, these results suggest that while the proportional odds assumption is not strictly met, the observed deviations appear minor and not practically consequential. An ordinal logistic model, while not ideal for interpretability, remains an adequate modeling choice for capturing the relationship between predictors and ordinal anxiety levels.\n\n\n------------------------------------------------------------ \nTest for            X2  df  probability \n------------------------------------------------------------ \nOmnibus             50.1    25  0\nStress.Level            14.11   5   0.01\nSleep.Hours         9.71    5   0.08\nCaffeine.Intake     17.07   5   0\nTherapy.Sessions        1.77    5   0.88\nFamily.History.of.AnxietyYes    4.26    5   0.51\n------------------------------------------------------------ \n\nH0: Parallel Regression Assumption holds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe next examine the linear regression model. Its results closely mirror those of the ordinal model: Sleep Hours shows a negative association with Anxiety Level, while Stress Level, Caffeine Intake, Therapy Sessions, and Family History of Anxiety all exhibit positive associations. The model’s \\(R^2\\) of 0.519 suggests moderate predictive power—consistent with the classification accuracy observed earlier. This alignment indicates that, despite its misspecification, the linear regression model effectively captures the main structure of the data.\n\n\n\nCall:\nlm(formula = Anxiety.Level ~ Stress.Level + Sleep.Hours + Caffeine.Intake + \n    Therapy.Sessions + Family.History.of.Anxiety, data = model_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.4311 -0.7081 -0.0281  0.6776  3.6825 \n\nCoefficients:\n                               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                   2.503e+00  7.171e-02  34.899  &lt; 2e-16 ***\nStress.Level                  3.385e-01  3.476e-03  97.379  &lt; 2e-16 ***\nSleep.Hours                  -2.296e-01  9.412e-03 -24.399  &lt; 2e-16 ***\nCaffeine.Intake               1.399e-03  7.171e-05  19.502  &lt; 2e-16 ***\nTherapy.Sessions              9.145e-02  6.957e-03  13.145  &lt; 2e-16 ***\nFamily.History.of.AnxietyYes  1.156e-01  2.437e-02   4.743 2.14e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9962 on 9980 degrees of freedom\nMultiple R-squared:  0.5194,    Adjusted R-squared:  0.5191 \nF-statistic:  2157 on 5 and 9980 DF,  p-value: &lt; 2.2e-16\n\n\nThe confusion matrix below also tells a similar story. The linear regression model achieves an accuracy of 37.6%, closely matching the ordinal model. Once again, the most frequent prediction for each true level is typically the correct one, no observations are predicted as an Anxiety Level of 7, and 87.3% of predictions fall within one level of the true value. Taken together, these results suggest that both models perform comparably.\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    1    2    3    4    5    6    7\n         1  105   52   14    4    0    0    0\n         2  687  755  520  146   15    3    0\n         3  222  749 1070  687  202   23    1\n         4   25  189  672 1133  725  169   27\n         5    0   11  131  437  657  384   80\n         6    0    0    0    9   30   37   15\n         7    0    0    0    0    0    0    0\n\nOverall Statistics\n                                          \n               Accuracy : 0.3762          \n                 95% CI : (0.3667, 0.3858)\n    No Information Rate : 0.2419          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.2103          \n                                          \n Mcnemar's Test P-Value : NA              \n\n\n\nCases predicted within one level of the true level: 87.27%\n\n\nHowever, where the linear regression model differs most from the ordinal logistic model is in its treatment of the extremes. The linear regression model severely underpredicts Classes 1 and 6. For instance, among cases truly labeled as 1, more are predicted as 3 than as 1; for true sixes, the model more frequently predicts a 4 than a 6. This reflects a well-known property of linear regression: a tendency to regress toward the mean.\nWhile alternative approaches such as weighted regression can reduce this issue, they do so by distorting the underlying data distribution or sacrificing interpretability—both of which conflict with our modeling goals. The ordinal logistic model also exhibits this bias, but to a lesser extent, owing to its structure that better respects ordinal spacing.\n\n\n\nAlthough the ordinal logistic model is statistically well-suited to ordered outcomes, its coefficients are often harder to interpret in practical terms. For example, the model estimates that:\n\nEach additional hour of sleep reduces the log-odds of reporting a higher anxiety level by 0.52.\n\nWhile this may be meaningful to a statistician, log-odds are abstract and unintuitive for most readers. Even when translated into odds ratios—about a 40% reduction in the odds of being in a higher anxiety category—the interpretation remains ambiguous. What does “higher category” mean in practice? And how much higher?\nMoreover, the phrase “reporting a higher anxiety level” is conceptually fuzzy for those unfamiliar with ordinal logistic regression—it doesn’t map cleanly onto expected values or real-number outcomes.\nBy contrast, the linear model produces a more direct and accessible statement:\n\nEach additional hour of sleep is associated with a 0.23-point decrease in expected anxiety level.\n\nThis clear mapping from input units to outcome makes the results more tangible—especially for non-technical audiences. The ability to express predictor effects in everyday terms was a key reason for ultimately favoring the linear model in this analysis, despite its formal misspecification and its limited reliability at the edges of the scale. As we’ll explore later, the predictions themselves are inherently fuzzy, further supporting our emphasis on interpretability over classification precision. In addition, by modeling high-anxiety individuals (levels 8–10) separately, we avoid the primary predictive risk—misclassifying the people most in need of identification—and allow the linear model to focus on the more stable patterns within the moderate anxiety range."
  },
  {
    "objectID": "statistical_supplements/low_to_moderate_regression.html#overview",
    "href": "statistical_supplements/low_to_moderate_regression.html#overview",
    "title": "Predicting across Low / Moderate Axniety Levels",
    "section": "",
    "text": "Exploratory plots revealed a strong relationship between Anxiety Level and Stress Level, providing early confidence in predictive modeling. However, before proceeding, we must consider the nature of our outcome variable. Anxiety Level is numerical, but ordinal—it has a meaningful order, but not necessarily equal spacing between categories. This complicates model selection, as linear regression assumes a continuous and unbounded outcome, where equal differences between values carry consistent meaning.\nWe consider two main modeling approaches:\n\nLinear regression with rounding, which is easy to interpret but not designed for ordinal data.\nOrdinal logistic regression (also known as the proportional odds model), which more accurately reflects the structure of the outcome but is harder to interpret clearly.\nAlternative ordinal modeling frameworks (e.g., partial proportional odds) were not explored, as they were beyond the scope of this analysis.\n\nAlthough ordinal logistic regression is more appropriate in theory, its interpretation can be opaque—especially for non-technical audiences. Linear regression, while a simplification, provides direct and intuitive estimates, making it better suited to our goals, which prioritize interpretability and transparency over statistical precision.\nThat said, we evaluate both models empirically before committing to one. Our first step is to determine which predictors to include. To guide this selection, we use permutation-based variable importance from a random forest model. The resulting plot highlights Stress Level as the most important feature. A noticeable elbow point in the importance scores—specifically between Family History of Anxiety and Occupation—provides a natural cutoff. Based on this, we include the following predictors: Stress Level, Sleep Hours, Caffeine Intake, Therapy Sessions, and Family History of Anxiety.\n\n\n\n\n\n\n\n\n\n\n\nFirst, we fit the ordinal logistic regression model. The results show a clear pattern: all predictors are directionally consistent with expectations. Stress Level, Caffeine Intake, Therapy Sessions, and Family History of Anxiety are positively associated with higher anxiety levels. In contrast, Sleep Hours has a negative association—more sleep corresponds to lower anxiety.\n\n\nCall:\npolr(formula = ordered(Anxiety.Level) ~ Stress.Level + Sleep.Hours + \n    Caffeine.Intake + Therapy.Sessions + Family.History.of.Anxiety, \n    data = model_data, Hess = TRUE)\n\nCoefficients:\n                                 Value Std. Error t value\nStress.Level                  0.608213  0.0085380  71.236\nSleep.Hours                  -0.421707  0.0177904 -23.704\nCaffeine.Intake               0.002571  0.0001345  19.119\nTherapy.Sessions              0.167046  0.0129053  12.944\nFamily.History.of.AnxietyYes  0.205308  0.0449721   4.565\n\nIntercepts:\n    Value    Std. Error t value \n1|2  -1.6484   0.1351   -12.1995\n2|3   0.0611   0.1328     0.4597\n3|4   1.7495   0.1345    13.0033\n4|5   3.4915   0.1382    25.2554\n5|6   5.3197   0.1436    37.0440\n6|7   7.3847   0.1664    44.3791\n\nResidual Deviance: 27852.94 \nAIC: 27874.94 \n\n\nThe confusion matrix below shows that the model performs modestly but meaningfully better than chance in predicting anxiety levels. The overall accuracy is 38.3%—well above the naïve baseline of predicting the majority class (24.2%). This performance is consistent with the challenges of modeling subjective human responses, where perfect classification is unlikely due to inherent noise and ambiguity.\nEncouragingly, for most predicted classes, the most common true label is the correct one, and 86.4% of predictions fall within one level of the actual value. This indicates that while the model may struggle with fine-grained distinctions, it captures the broader structure of the outcome effectively.\nOne notable limitation is the model’s complete failure to predict Anxiety Level 7—the rarest category, with only 123 cases out of 9,986. This likely reflects both class imbalance and the ordinal model’s tendency to shrink predictions toward the center of the scale. Potential remedies include reweighting, resampling, or alternative modeling strategies that better account for the tails of the distribution.\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    1    2    3    4    5    6    7\n         1  332  205   87   17    1    0    0\n         2  484  661  509  154   22    3    0\n         3  198  682  995  639  187   22    1\n         4   25  193  659 1107  686  158   23\n         5    0   15  156  485  681  385   80\n         6    0    0    1   14   52   48   19\n         7    0    0    0    0    0    0    0\n\nOverall Statistics\n                                          \n               Accuracy : 0.3829          \n                 95% CI : (0.3734, 0.3926)\n    No Information Rate : 0.2419          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.2247          \n                                          \n Mcnemar's Test P-Value : NA              \n\n\n\nCases predicted within one level of the true level: 86.41%\n\n\n\n\nWe formally tested the proportional odds assumption using the Brant test. The omnibus test was significant, indicating that the assumption does not hold strictly. At the individual level, Stress Level, Sleep Hours, and Caffeine Intake also showed statistically significant violations.\nHowever, visual inspection of the empirical cumulative logits for each predictor revealed near-parallel trends across thresholds, broadly consistent with the proportional odds framework. A slight divergence in slope between the Anxiety ≥ 2 and Anxiety ≥ 3 thresholds is visible—particularly for Stress Level—suggesting mild non-proportionality at the lower end of the anxiety scale. Additionally, the slope for Anxiety ≥ 7 behaves somewhat erratically, likely due to extreme class imbalance at the highest anxiety level.\nTaken together, these results suggest that while the proportional odds assumption is not strictly met, the observed deviations appear minor and not practically consequential. An ordinal logistic model, while not ideal for interpretability, remains an adequate modeling choice for capturing the relationship between predictors and ordinal anxiety levels.\n\n\n------------------------------------------------------------ \nTest for            X2  df  probability \n------------------------------------------------------------ \nOmnibus             50.1    25  0\nStress.Level            14.11   5   0.01\nSleep.Hours         9.71    5   0.08\nCaffeine.Intake     17.07   5   0\nTherapy.Sessions        1.77    5   0.88\nFamily.History.of.AnxietyYes    4.26    5   0.51\n------------------------------------------------------------ \n\nH0: Parallel Regression Assumption holds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe next examine the linear regression model. Its results closely mirror those of the ordinal model: Sleep Hours shows a negative association with Anxiety Level, while Stress Level, Caffeine Intake, Therapy Sessions, and Family History of Anxiety all exhibit positive associations. The model’s \\(R^2\\) of 0.519 suggests moderate predictive power—consistent with the classification accuracy observed earlier. This alignment indicates that, despite its misspecification, the linear regression model effectively captures the main structure of the data.\n\n\n\nCall:\nlm(formula = Anxiety.Level ~ Stress.Level + Sleep.Hours + Caffeine.Intake + \n    Therapy.Sessions + Family.History.of.Anxiety, data = model_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.4311 -0.7081 -0.0281  0.6776  3.6825 \n\nCoefficients:\n                               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                   2.503e+00  7.171e-02  34.899  &lt; 2e-16 ***\nStress.Level                  3.385e-01  3.476e-03  97.379  &lt; 2e-16 ***\nSleep.Hours                  -2.296e-01  9.412e-03 -24.399  &lt; 2e-16 ***\nCaffeine.Intake               1.399e-03  7.171e-05  19.502  &lt; 2e-16 ***\nTherapy.Sessions              9.145e-02  6.957e-03  13.145  &lt; 2e-16 ***\nFamily.History.of.AnxietyYes  1.156e-01  2.437e-02   4.743 2.14e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9962 on 9980 degrees of freedom\nMultiple R-squared:  0.5194,    Adjusted R-squared:  0.5191 \nF-statistic:  2157 on 5 and 9980 DF,  p-value: &lt; 2.2e-16\n\n\nThe confusion matrix below also tells a similar story. The linear regression model achieves an accuracy of 37.6%, closely matching the ordinal model. Once again, the most frequent prediction for each true level is typically the correct one, no observations are predicted as an Anxiety Level of 7, and 87.3% of predictions fall within one level of the true value. Taken together, these results suggest that both models perform comparably.\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    1    2    3    4    5    6    7\n         1  105   52   14    4    0    0    0\n         2  687  755  520  146   15    3    0\n         3  222  749 1070  687  202   23    1\n         4   25  189  672 1133  725  169   27\n         5    0   11  131  437  657  384   80\n         6    0    0    0    9   30   37   15\n         7    0    0    0    0    0    0    0\n\nOverall Statistics\n                                          \n               Accuracy : 0.3762          \n                 95% CI : (0.3667, 0.3858)\n    No Information Rate : 0.2419          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.2103          \n                                          \n Mcnemar's Test P-Value : NA              \n\n\n\nCases predicted within one level of the true level: 87.27%\n\n\nHowever, where the linear regression model differs most from the ordinal logistic model is in its treatment of the extremes. The linear regression model severely underpredicts Classes 1 and 6. For instance, among cases truly labeled as 1, more are predicted as 3 than as 1; for true sixes, the model more frequently predicts a 4 than a 6. This reflects a well-known property of linear regression: a tendency to regress toward the mean.\nWhile alternative approaches such as weighted regression can reduce this issue, they do so by distorting the underlying data distribution or sacrificing interpretability—both of which conflict with our modeling goals. The ordinal logistic model also exhibits this bias, but to a lesser extent, owing to its structure that better respects ordinal spacing.\n\n\n\nAlthough the ordinal logistic model is statistically well-suited to ordered outcomes, its coefficients are often harder to interpret in practical terms. For example, the model estimates that:\n\nEach additional hour of sleep reduces the log-odds of reporting a higher anxiety level by 0.52.\n\nWhile this may be meaningful to a statistician, log-odds are abstract and unintuitive for most readers. Even when translated into odds ratios—about a 40% reduction in the odds of being in a higher anxiety category—the interpretation remains ambiguous. What does “higher category” mean in practice? And how much higher?\nMoreover, the phrase “reporting a higher anxiety level” is conceptually fuzzy for those unfamiliar with ordinal logistic regression—it doesn’t map cleanly onto expected values or real-number outcomes.\nBy contrast, the linear model produces a more direct and accessible statement:\n\nEach additional hour of sleep is associated with a 0.23-point decrease in expected anxiety level.\n\nThis clear mapping from input units to outcome makes the results more tangible—especially for non-technical audiences. The ability to express predictor effects in everyday terms was a key reason for ultimately favoring the linear model in this analysis, despite its formal misspecification and its limited reliability at the edges of the scale. As we’ll explore later, the predictions themselves are inherently fuzzy, further supporting our emphasis on interpretability over classification precision. In addition, by modeling high-anxiety individuals (levels 8–10) separately, we avoid the primary predictive risk—misclassifying the people most in need of identification—and allow the linear model to focus on the more stable patterns within the moderate anxiety range."
  },
  {
    "objectID": "statistical_supplements/low_to_moderate_regression.html#model-selection",
    "href": "statistical_supplements/low_to_moderate_regression.html#model-selection",
    "title": "Predicting across Low / Moderate Axniety Levels",
    "section": "Model Selection",
    "text": "Model Selection\nNow that we’ve selected linear regression as our preferred model—prioritizing parsimony and interpretability—we begin with a baseline that includes Stress Level, Sleep Hours, Caffeine Intake, Therapy Sessions, and Family History of Anxiety, based on prior feature importance analysis.\nNext, we assess whether any of these variables should be removed or if others should be added.\n\nRemoving Variables\nTo evaluate whether each predictor meaningfully contributes to the model, we compare BIC and Bayes Factor values after individually dropping each one.\nThe results below suggest that Stress Level is indispensable (as expected), with a BIC increase of nearly 7,000 when removed. Sleep Hours, Caffeine Intake, and Therapy Sessions also show strong support for inclusion based on substantial BIC increases and Bayes Factors.\nFamily History of Anxiety presents weaker evidence, but the change is still large enough to justify its retention under the principle of parsimony—each variable adds unique explanatory value without unnecessarily inflating model complexity.\n\n\nStress Level:\n\n\n                      aic      bic bayes.factor      p   rsq adj.rsq\nsimplified_model 34938.68 34981.93            0 &lt;2e-16 0.063   0.062\nlinear_model     28270.88 28321.34          Inf        0.519   0.519\n\n\nSleep Hours:\n\n\n                      aic      bic  bayes.factor      p   rsq adj.rsq\nsimplified_model 28847.44 28890.69  0.000000e+00 &lt;2e-16 0.491   0.490\nlinear_model     28270.88 28321.34 4.293248e+123        0.519   0.519\n\n\nCaffeine Intake:\n\n\n                      aic      bic bayes.factor      p   rsq adj.rsq\nsimplified_model 28642.38 28685.64 0.000000e+00 &lt;2e-16 0.501   0.501\nlinear_model     28270.88 28321.34 1.274688e+79        0.519   0.519\n\n\nTherapy Sessions:\n\n\n                      aic      bic bayes.factor      p   rsq adj.rsq\nsimplified_model 28440.29 28483.54 0.000000e+00 &lt;2e-16 0.511   0.511\nlinear_model     28270.88 28321.34 1.665933e+35        0.519   0.519\n\n\nFamily History of Anxiety:\n\n\n                      aic      bic bayes.factor      p   rsq adj.rsq\nsimplified_model 28291.36 28334.62        0.001 &lt;2e-16 0.518   0.518\nlinear_model     28270.88 28321.34      762.941        0.519   0.519\n\n\n\n\nAdding Variables\nTo test whether the model could benefit from an additional predictor, we examine the next-highest ranked variable from the feature importance analysis: Occupation.\nAdding Occupation results in a higher BIC and a Bayes Factor favoring the original model, indicating that its inclusion does not improve model fit enough to justify the added complexity. This supports our earlier decision to treat Occupation as beyond the importance elbow point.\nGiven this result, we retain the original model as our final specification for this analysis.\n\n\n                      aic      bic bayes.factor     p   rsq adj.rsq\nlinear_model     28270.88 28321.34 4.912824e+21 0.563 0.519   0.519\noccupation_added 28284.27 28421.24 0.000000e+00       0.520   0.519"
  },
  {
    "objectID": "statistical_supplements/low_to_moderate_regression.html#model-diagnostics",
    "href": "statistical_supplements/low_to_moderate_regression.html#model-diagnostics",
    "title": "Predicting across Low / Moderate Axniety Levels",
    "section": "Model Diagnostics",
    "text": "Model Diagnostics\nWith our model selected, we now assess its diagnostics to ensure the assumptions of linear regression are reasonably satisfied and that the results are stable and interpretable. This section is organized around four diagnostic pillars:\n\nError distribution checks, including assessments of normality and homoskedasticity. While formal inference is not our focus, these checks help us understand residual behavior and identify potential misspecification.\nOutlier analysis, which helps detect individual observations with high influence or poor fit that may distort coefficient estimates.\nStructural assumption checks, covering linearity, additivity (no interaction terms), and multicollinearity, to confirm that the model’s functional form is appropriate for the data.\nCalibration assessment, which ensures that predicted values align with observed responses and reflect meaningful expected outcomes.\n\n\nNormality of Errors\nThe Q-Q plot shows slight “S-bending” near the tails, indicating mild deviations from perfect normality—likely due to applying linear regression to a bounded ordinal outcome. However, the residuals remain approximately symmetric, with no significant skewness or heavy tails.\n\n\nWarning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(density)` instead.\n\n\n\n\n\n\n\n\n\n\n\nHomoskedasticity of Errors\nDue to the discrete and bounded nature of the outcome, the residual plot displays clear banding patterns—an expected artifact of applying linear regression to ordinal data. Nevertheless, the LOESS smoother remains essentially flat, indicating no substantial heteroskedasticity.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nOutlier Detection\nTo explore this possibility, we’re using the same plots as in the logistic model (with the appropriate changes)\nThe four plots include:\n\nLeverage vs. Cook’s Distance\nPredicted Anxiety vs. Studentized Residuals\nLeverage vs. Studentized Residuals\nCook’s Distance by Observation Index\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMost observations appear well behaved, with no evidence of influential outliers. Cook’s distances are uniformly low (maximum &lt; 0.003), indicating no individual point exerts undue influence on the model’s estimates. A small number of observations exceed the ±3 threshold for studentized residuals, which is expected in a dataset of this size. These high-residual points generally have low leverage and do not coincide with extreme influence measures.\nThe absence of high-leverage, high-residual combinations, combined with the overall stability of influence metrics, suggests that the model is not disproportionately shaped by any small subset of observations. While residual banding is present due to the ordinal nature of the outcome, it does not raise concern about outlier-driven distortion.\nA few observations did exhibit either larger residuals or higher-than-average leverage, but none met criteria for being both poorly predicted and highly influential. These points were retained, as they are consistent with the expected variability in the data and do not materially affect model fit.\n\n\nLinearity\nSince linearity concerns only numerical predictors, there is no need to assess this assumption for categorical variables such as Family History of Anxiety. For the remaining continuous predictors, plots of each variable against predicted anxiety show strong linear trends. Although slight deviations appear in the tails—particularly at extreme values—these are minor and do not suggest meaningful nonlinearity.\n\n\n\n\n\n\n\n\n\n\n\nAdditivity\nA likelihood ratio test showed no evidence that including interaction terms improves model fit (p = 0.84), suggesting that additivity is a reasonable working assumption for this analysis. While interactions could exist, their effects appear negligible in this context.\n\n\nAnalysis of Variance Table\n\nModel 1: Anxiety.Level ~ Stress.Level + Sleep.Hours + Caffeine.Intake + \n    Therapy.Sessions + Family.History.of.Anxiety\nModel 2: Anxiety.Level ~ (Stress.Level + Sleep.Hours + Caffeine.Intake + \n    Therapy.Sessions + Family.History.of.Anxiety)^2\n  Res.Df    RSS Df Sum of Sq Pr(&gt;Chi)\n1   9980 9904.2                      \n2   9970 9898.5 10    5.6562     0.84\n\n\n\n\nNo Multicollinearity\nAll predictors in the model have variance inflation factors (VIFs) below 1.5—well below the commonly used threshold of 5. This suggests that multicollinearity is not a concern and that the predictors are sufficiently independent to yield stable, interpretable coefficients.\n\n\nVariance Inflation Factors:\n\n\n             Stress.Level               Sleep.Hours           Caffeine.Intake \n                 1.000231                  1.001329                  1.000781 \n         Therapy.Sessions Family.History.of.Anxiety \n                 1.493893                  1.493447 \n\n\n\n\nModel Calibration\nBecause our goal is interpretation, it’s essential to verify that the model’s predicted values are meaningful representations of expected outcomes. A predicted Anxiety Level of 5.4, while not an actual possible score, reflects the expected value for someone with those characteristics. For the predicted values to be interpretable, the model must be well-calibrated—that is, predictions should closely align with the average observed outcomes.\nTo assess calibration, we compared the model’s predictions to the actual mean Anxiety Levels within quantile-based bins of predicted values. The resulting calibration plot shows a near-perfect alignment along the identity line, suggesting that the model’s predictions closely approximate average observed outcomes across the range of predicted values. This supports the claim that the linear regression model provides reliable and interpretable estimates across the full range of predictions\n\n\n\n\n\n\n\n\n\n\n\nFinal Model Summary\nDespite the model’s intentional misspecification—applying linear regression to a bounded ordinal outcome—diagnostics suggest that all key assumptions are reasonably satisfied. Residuals are approximately normal and homoskedastic. No influential outliers are present, and both linearity and additivity hold for the numeric predictors. Multicollinearity is negligible.. Taken together, these results indicate that the model is stable and interpretable, and that the tradeoff in favor of simplicity has not compromised its validity for exploratory or communicative purposes."
  },
  {
    "objectID": "statistical_supplements/low_to_moderate_regression.html#from-regression-to-classification",
    "href": "statistical_supplements/low_to_moderate_regression.html#from-regression-to-classification",
    "title": "Predicting across Low / Moderate Axniety Levels",
    "section": "From Regression to Classification",
    "text": "From Regression to Classification\nTo convert the linear regression model’s continuous predictions into discrete classes, we apply simple rounding. While this may reduce predictive precision, it avoids the added complexity of optimizing thresholds—especially since such methods often bias results toward the majority class in boundary regions.\n\nClassification Performance\nAlthough we previously reviewed classification performance in the overview section, we briefly revisit the results here for context.\n\nThe linear regression model achieves an accuracy of 0.376, closely matching the ordinal model. Once again, the most frequent prediction for each true level is typically the correct one, no observations are predicted as an Anxiety Level of 7, and 87.27% of predictions fall within one level of the true value.\n\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    1    2    3    4    5    6    7\n         1  105   52   14    4    0    0    0\n         2  687  755  520  146   15    3    0\n         3  222  749 1070  687  202   23    1\n         4   25  189  672 1133  725  169   27\n         5    0   11  131  437  657  384   80\n         6    0    0    0    9   30   37   15\n         7    0    0    0    0    0    0    0\n\nOverall Statistics\n                                          \n               Accuracy : 0.3762          \n                 95% CI : (0.3667, 0.3858)\n    No Information Rate : 0.2419          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.2103          \n                                          \n Mcnemar's Test P-Value : NA              \n\n\n\nCases predicted within one level of the true level: 87.27%\n\n\nNow that we’ve revisited the results, let’s take a closer look at the within-one accuracy metric. At first glance, this may seem like an overly generous statistic. However, it’s important to recognize that humans tend to struggle to reliably distinguish between adjacent levels on fine-grained ordinal scales—especially when the number of levels exceeds 7.\n\n“Humans have difficulty reliably distinguishing between more than 5 to 7 categories on a rating scale, with reliability and interpretability decreasing as the number of levels increases.” — Miller, G. A. (1956). “The Magical Number Seven, Plus or Minus Two: Some Limits on Our Capacity for Processing Information.” Psychological Review, 63(2), 81–97.\n\nAlthough our model is trained on a 1–7 scale, the original data was recorded on a 1–10 scale, likely introducing subjective noise and imprecision in how respondents rated themselves. In this context, a within-one accuracy of 87% better captures the model’s practical performance than strict classification accuracy.\nThat said, this metric is indeed optimistic, and we acknowledge its limitations. Still, given the inherent ambiguity in human-rated scales, within-one accuracy offers a more forgiving and arguably more realistic view of model effectiveness.\n\n\nProbabilistic Framing\nMoreover, from the diagnostics we know that the errors roughly follow a normal distribution. Actually, they roughly follow a standard normal distribution, which gives us the following insights:\n\nResiduals within ±0.5 (i.e., correct prediction after rounding): 37.62%\nResiduals within ±1.0 (empirical rule ≈ 68%): 67.31%\nResiduals within ±1.5 (within-one threshold for classification): 87.27%\nResiduals within ±2.0 (empirical rule ≈ 95%): 95.79%\n\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nWarning in annotate(\"text\", x = 0.55, y = 600, label = \"±0.5 (Correct\nPrediction)\", : Ignoring unknown parameters: `linewidth`\n\n\nWarning in annotate(\"text\", x = 1.55, y = 550, label = \"±1.5 (Within-One\nPrediction)\", : Ignoring unknown parameters: `linewidth`\n\n\n\n\n\n\n\n\n\nThe residuals from the linear regression model approximate a normal distribution, which supports our use of the Gaussian framework to describe prediction uncertainty. That said, this behavior reflects both the underlying signal and the constraints of modeling a bounded ordinal outcome with a continuous method. In particular, residuals near the edges of the anxiety scale (1 and 7) are limited by ceiling and floor effects, which may distort the distribution’s tails.\nFor this reason, the normal approximation should be seen as a useful simplification rather than a strict assumption. It allows us to frame uncertainty in relatable terms (e.g., “usually within ±1”), while recognizing that such interpretations are approximate. In this exploratory context, we find that this framing aids communication without meaningfully distorting the model’s behavior."
  },
  {
    "objectID": "statistical_supplements/low_to_moderate_regression.html#interpreting-the-final-model",
    "href": "statistical_supplements/low_to_moderate_regression.html#interpreting-the-final-model",
    "title": "Predicting across Low / Moderate Axniety Levels",
    "section": "Interpreting the Final Model",
    "text": "Interpreting the Final Model\n\nPredictor Effects\nNow that we’re confident in the quality of our model, let’s take a closer look at the regression equation:\n\n\n\nCall:\nlm(formula = Anxiety.Level ~ Stress.Level + Sleep.Hours + Caffeine.Intake + \n    Therapy.Sessions + Family.History.of.Anxiety, data = model_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.4311 -0.7081 -0.0281  0.6776  3.6825 \n\nCoefficients:\n                               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                   2.503e+00  7.171e-02  34.899  &lt; 2e-16 ***\nStress.Level                  3.385e-01  3.476e-03  97.379  &lt; 2e-16 ***\nSleep.Hours                  -2.296e-01  9.412e-03 -24.399  &lt; 2e-16 ***\nCaffeine.Intake               1.399e-03  7.171e-05  19.502  &lt; 2e-16 ***\nTherapy.Sessions              9.145e-02  6.957e-03  13.145  &lt; 2e-16 ***\nFamily.History.of.AnxietyYes  1.156e-01  2.437e-02   4.743 2.14e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9962 on 9980 degrees of freedom\nMultiple R-squared:  0.5194,    Adjusted R-squared:  0.5191 \nF-statistic:  2157 on 5 and 9980 DF,  p-value: &lt; 2.2e-16\n\n\n\\[\n\\begin{align*}\n\\widehat{\\text{Anxiety Level}} =\\ & 2.503 \\\\\n&+ 0.339\\ \\cdot\\ \\text{Stress Level} \\\\\n&- 0.230\\ \\cdot\\ \\text{Sleep Hours} \\\\\n&+ 0.00140\\ \\cdot\\ \\text{Caffeine Intake} \\\\\n&+ 0.0915\\ \\cdot\\ \\text{Therapy Sessions} \\\\\n&+ 0.116\\ \\cdot\\ \\text{Family History of Anxiety}_{\\text{Yes}}\n\\end{align*}\n\\]\nThe accompanying interpretations are as follows:\n\nEach additional Stress Level increases the expected Anxiety Level by 0.339, holding all other variables constant.\nEach additional hour of Sleep decreases the expected Anxiety Level by 0.230, holding all other variables constant.\nEach additional Therapy Session increases the expected Anxiety Level by 0.0915, holding all other variables constant.\nEach additional milligram of Caffeine increases the expected Anxiety Level by 0.00140, holding all other variables constant. In practical terms, an additional cup of coffee (≈100 mg) increases the expected Anxiety Level by 0.140.\nIndividuals with a Family History of Anxiety predicted to score 0.116 points higher on the Anxiety Level scale than those without, controlling for the other variables.\n\nWhile the scale of the traditional interpretation doesn’t yield a straightforward one-to-one correspondence between predictors and Anxiety Levels, it still offers valuable insight: anxiety is multifaceted, and no single variable fully explains it.\n\nWhen we increased Stress Level by 3 units, while holding all else constant, the predicted Anxiety Level increased by about 1 point. Similarly, increasing Sleep Hours by 4 led to roughly a 1-point decrease in predicted Anxiety. These align closely with the effect sizes in the model and illustrate the trade-offs.\nIn contrast, it would take about 10 additional therapy sessions or the equivalent of 7 extra cups of coffee to shift the predicted Anxiety Level by just 1 point. This confirms that while statistically significant, these variables have relatively modest effects in practical terms.\nAs for Family History of Anxiety, the model predicts a small increase—just over a tenth of a point. However, in cases where someone’s predicted anxiety is right on the edge between two categories, this small nudge can be enough to shift the prediction from one level to the next. So, while not a strong driver on its own, it may still influence certain borderline predictions.\n\nThis, however, does not mean that variables like Therapy Sessions, Caffeine Intake, and Family History are irrelevant to prediction—only that their individual effects on Anxiety Level are modest.\n\n\nSimplified Model Comparison\nTo assess the contribution of lower-impact variables, we fit a simplified linear model using only Stress Level and Sleep Hours. While this model maintained comparable overall accuracy (35.7%) and within-one accuracy (85.5%), it struggled even more at the extremes—particularly for Classes 1 and 6—further emphasizing the linear model’s tendency to regress toward the mean. This comparison reinforces that even modest predictors can improve edge-case performance and stabilize the model’s behavior, supporting their inclusion.\n\n\n\nCall:\nlm(formula = Anxiety.Level ~ Stress.Level + Sleep.Hours, data = model_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.6466 -0.7463 -0.0211  0.7093  3.8968 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   3.119006   0.070439   44.28   &lt;2e-16 ***\nStress.Level  0.338262   0.003609   93.72   &lt;2e-16 ***\nSleep.Hours  -0.229016   0.009769  -23.44   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.034 on 9983 degrees of freedom\nMultiple R-squared:  0.4815,    Adjusted R-squared:  0.4814 \nF-statistic:  4636 on 2 and 9983 DF,  p-value: &lt; 2.2e-16\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    1    2    3    4    5    6    7\n         1   36   12    5    1    0    0    0\n         2  712  769  527  155   19    3    0\n         3  261  751 1049  722  229   25    3\n         4   29  209  660 1080  728  208   36\n         5    1   15  165  457  645  377   84\n         6    0    0    1    1    8    3    0\n         7    0    0    0    0    0    0    0\n\nOverall Statistics\n                                          \n               Accuracy : 0.3587          \n                 95% CI : (0.3493, 0.3682)\n    No Information Rate : 0.2419          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.1857          \n                                          \n Mcnemar's Test P-Value : NA              \n\n\n\nCases predicted within one level of the true level: 85.48%"
  },
  {
    "objectID": "statistical_supplements/low_to_moderate_regression.html#conclusion",
    "href": "statistical_supplements/low_to_moderate_regression.html#conclusion",
    "title": "Predicting across Low / Moderate Axniety Levels",
    "section": "Conclusion",
    "text": "Conclusion\nIn modeling moderate anxiety levels (1–7), we evaluated both ordinal logistic regression and linear regression. While the ordinal approach more closely matches the structure of the outcome variable, it posed interpretive challenges and did not offer meaningful improvements in predictive performance. The linear model, despite its formal misspecification, produced comparable accuracy, more transparent diagnostics, and a direct mapping from predictors to expected values—making it the more appropriate choice given the goals of this analysis.\nThe final model revealed consistent and intuitive relationships: higher stress, greater caffeine intake, more therapy sessions, and a family history of anxiety were all associated with increased anxiety levels, while more sleep was linked to lower levels. Although the individual effects were modest, together they provided a stable and interpretable picture of the factors most associated with anxiety in this dataset. Diagnostic checks supported the model’s overall validity: residuals were well-behaved, multicollinearity was negligible, and most predictions fell within one level of the true anxiety score.\nWhile the linear model underpredicts at the extremes—particularly for rare or low-frequency anxiety levels—this limitation is expected given the bounded, subjective nature of the response variable. A strictly ordinal logistic model, while more theoretically appropriate, would have constrained our ability to inspect residual behavior and model calibration in the same interpretable way. Ultimately, the linear regression model strikes a practical balance between statistical structure and communicative clarity."
  },
  {
    "objectID": "statistical_supplements/high_anxiety.html",
    "href": "statistical_supplements/high_anxiety.html",
    "title": "Failing to Predict across High Anxiety Levels",
    "section": "",
    "text": "Exploratory analysis revealed little evidence of a relationship between high anxiety levels (8–10) and the available predictors, raising concerns about whether these classes contain enough signal to support meaningful modeling."
  },
  {
    "objectID": "statistical_supplements/high_anxiety.html#mutual-information-for-anxiety-level-8-10",
    "href": "statistical_supplements/high_anxiety.html#mutual-information-for-anxiety-level-8-10",
    "title": "Failing to Predict across High Anxiety Levels",
    "section": "Mutual Information for Anxiety Level (8-10)",
    "text": "Mutual Information for Anxiety Level (8-10)\nTo evaluate this more formally, we computed the mutual information between Anxiety Level and each predictor—a measure of how much information a feature provides about the target. All values were approximately 0.01 or lower, indicating minimal predictive power.\n\n\n\n\n\n\n\n\n\nPermutation tests confirmed these results. Only one predictor—Diet Quality—yielded a statistically significant mutual information score (MI ≈ 0.01, p &lt; 0.01), suggesting a weak but detectable association. However, the effect is negligible in practical terms. All other predictors had MI &lt; 0.01 and p-values &gt; 0.10, reinforcing the conclusion that high anxiety levels cannot be reliably predicted from the available features."
  },
  {
    "objectID": "statistical_supplements/high_anxiety.html#trying-to-overfit-a-model",
    "href": "statistical_supplements/high_anxiety.html#trying-to-overfit-a-model",
    "title": "Failing to Predict across High Anxiety Levels",
    "section": "Trying to Overfit a Model",
    "text": "Trying to Overfit a Model\nAs a diagnostic exercise, we intentionally overfit a decision tree model to probe for residual signal, using highly permissive parameters (mincriterion = 0.5, minsplit = 5). The outcome (Anxiety Level 8–10) was treated as categorical to increase sensitivity to subtle distinctions.\nEven with relaxed constraints, the tree produced no splits—implying that no features provided even marginal discriminatory value. The confusion matrix confirms this: the model defaulted to predicting the majority class (8) for all observations, relying entirely on class frequency rather than learned structure.\n\n\n\n\n\n\n\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   8   9  10\n        8  363 329 322\n        9    0   0   0\n        10   0   0   0\n\nOverall Statistics\n                                          \n               Accuracy : 0.358           \n                 95% CI : (0.3284, 0.3884)\n    No Information Rate : 0.358           \n    P-Value [Acc &gt; NIR] : 0.5118          \n                                          \n                  Kappa : 0               \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: 8 Class: 9 Class: 10\nSensitivity             1.000   0.0000    0.0000\nSpecificity             0.000   1.0000    1.0000\nPos Pred Value          0.358      NaN       NaN\nNeg Pred Value            NaN   0.6755    0.6824\nPrevalence              0.358   0.3245    0.3176\nDetection Rate          0.358   0.0000    0.0000\nDetection Prevalence    1.000   0.0000    0.0000\nBalanced Accuracy       0.500   0.5000    0.5000"
  },
  {
    "objectID": "statistical_supplements/high_anxiety.html#conclusion",
    "href": "statistical_supplements/high_anxiety.html#conclusion",
    "title": "Failing to Predict across High Anxiety Levels",
    "section": "Conclusion",
    "text": "Conclusion\nThe consistent failure of both information-theoretic and model-based methods confirms that anxiety levels 8–10 cannot be reliably distinguished from one another based on the available predictors. These observations form an indistinct cluster with no usable internal structure. Accordingly, we model them as a single high-anxiety class using binary logistic regression. For all remaining levels, we apply a separate linear regression to capture finer-grained variation. This stacked modeling approach respects the limits of the data while maximizing interpretability where possible."
  },
  {
    "objectID": "reflection.html",
    "href": "reflection.html",
    "title": "Reflection",
    "section": "",
    "text": "I took on this project because mental health is something I care deeply about — and I wanted to challenge myself by diving into a real analysis without hand-holding. This was my first independent project outside of a school setting. I had high expectations for myself and held the work to a high standard. More than anything, I wanted a project I could add to my portfolio to demonstrate that I understand statistics — not just use them.\nBecause I believe learning is a continuous process, I’m also sharing my self-criticisms from this project below. If you have feedback or suggestions, feel free to connect with me on LinkedIn and send me a message — I’d love to hear your thoughts!"
  },
  {
    "objectID": "reflection.html#motivation",
    "href": "reflection.html#motivation",
    "title": "Reflection",
    "section": "",
    "text": "I took on this project because mental health is something I care deeply about — and I wanted to challenge myself by diving into a real analysis without hand-holding. This was my first independent project outside of a school setting. I had high expectations for myself and held the work to a high standard. More than anything, I wanted a project I could add to my portfolio to demonstrate that I understand statistics — not just use them.\nBecause I believe learning is a continuous process, I’m also sharing my self-criticisms from this project below. If you have feedback or suggestions, feel free to connect with me on LinkedIn and send me a message — I’d love to hear your thoughts!"
  },
  {
    "objectID": "reflection.html#improvements",
    "href": "reflection.html#improvements",
    "title": "Reflection",
    "section": "Improvements",
    "text": "Improvements\n\nTrain/test split:\nI’ll be honest — I was so eager to jump into modeling that I forgot about this step until I was already deep into the analysis. At that point, adding it retroactively felt dishonest. That said, my sample size was large enough that I should have done a proper train/validation/test split. A validation set would have been especially useful for model selection.\nUse statistics more consistently:\nI was inconsistent in how I applied statistical tools. Sometimes I minimized statistical tests in favor of “interpretability”, and other times I leaned on them heavily (like the linear model’s additivity test). In future projects, I want to be more principled and consistent in how I use statistical reasoning.\nDon’t force symmetry between models:\nI spent too much time trying to keep the logistic and linear analyses aligned. But these are fundamentally different models with different strengths, assumptions, and workflows. Next time, I’ll let each model do what it does best — rather than trying to make them mirror each other.\nAvoid tool-driven decisions:\nI sometimes made modeling choices based on what tools I wanted to showcase rather than what the problem required. That’s like trying to fix a faucet with your entire toolbox — some tools are helpful, others just get in the way. Going forward, I’ll be more mindful of what I need to do, instead of just what I can do."
  },
  {
    "objectID": "reflection.html#lessons-learned",
    "href": "reflection.html#lessons-learned",
    "title": "Reflection",
    "section": "Lessons Learned",
    "text": "Lessons Learned\n\nIt’s hard to balance rigor and accessibility.\nI often sacrificed statistical rigor in the name of communication — then justified those choices under the banner of “interpretability.” Ironically, I ended up explaining interactions anyway, so there wasn’t a compelling reason to stick with the simpler additive model. Looking back, those trade-offs deserved more honest and deliberate framing.\nI also struggled with tone while writing for a general audience — frequently brushing up against condescension, oversimplification, or sounding overly didactic. It’s surprisingly difficult to explain advanced statistical ideas clearly without either talking down or overwhelming the reader. I made the mistake of starting from the model and then trying to adapt the explanation to fit the audience. In hindsight, I should have started with the audience in mind, and then chosen the modeling approach that best communicated the patterns for them.\nWorking alone is both rewarding and limiting.\nI spent a lot of time second-guessing myself, digging through websites, forums, and videos to understand the norms and edge cases for different approaches. Having someone to talk to — even just to bounce ideas off — would have saved time and built confidence. Still, doing the project solo was a valuable growth experience."
  },
  {
    "objectID": "reflection.html#other-questions",
    "href": "reflection.html#other-questions",
    "title": "Reflection",
    "section": "Other Questions",
    "text": "Other Questions\n\nWhy not use decision trees?\nTrees are another interpretable model, but they focus on capturing local patterns. In contrast, regression models tend to summarize global trends. My exploratory analysis suggested this was a globally structured problem. While I did test both a regression tree and a classification tree, they required tens of splits to approximate the patterns — making them harder to interpret. In the end, trees were a valid alternative, but didn’t serve my goals as well.\nWhy use permutation importance?\nI had just learned about it and wanted to try it out. I was drawn to it because earlier model selection methods I’d used (like stepwise selection) often felt too prone to overfitting by adding too many variables. Permutation importance gave me simpler models that conveyed nearly the same insights. However, I now realize I introduced data leakage by calculating it using the full model. I also should’ve paired it with diagnostic plots to better communicate what was happening."
  },
  {
    "objectID": "reflection.html#conclusion",
    "href": "reflection.html#conclusion",
    "title": "Reflection",
    "section": "Conclusion",
    "text": "Conclusion\nGiven the circumstances and goals, I’d give myself a B+. I accomplished what I set out to do — but also made some major oversights along the way. That said, this project challenged me, taught me a great deal, and gave me a chance to reflect critically on my own process. I consider that a success, and a meaningful step forward in my growth as a data scientist. And honestly — I had fun tackling the challenges, puzzling through the trade-offs, and seeing the analysis come together."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Exploring the Link Between Lifestyle and Anxiety",
    "section": "",
    "text": "As a data scientist — and someone who personally struggles with anxiety — I wanted to explore something both meaningful to me and full of real-world complexity.\nThis project looks at how anxiety tends to show up alongside everyday habits — things like stress, sleep, caffeine, and diet. It’s not about diagnosing anyone. Instead, the goal is to spot patterns that appear again and again — clues that might help us understand anxiety a little better and talk about it more clearly.\nTo do this, I used Nate Zhang’s Social Anxiety Dataset, a synthetic dataset built for research. While it doesn’t contain real people’s data, it mirrors patterns found in actual surveys — making it a safe and realistic starting point for exploring how lifestyle might relate to anxiety."
  },
  {
    "objectID": "index.html#motivation",
    "href": "index.html#motivation",
    "title": "Exploring the Link Between Lifestyle and Anxiety",
    "section": "",
    "text": "As a data scientist — and someone who personally struggles with anxiety — I wanted to explore something both meaningful to me and full of real-world complexity.\nThis project looks at how anxiety tends to show up alongside everyday habits — things like stress, sleep, caffeine, and diet. It’s not about diagnosing anyone. Instead, the goal is to spot patterns that appear again and again — clues that might help us understand anxiety a little better and talk about it more clearly.\nTo do this, I used Nate Zhang’s Social Anxiety Dataset, a synthetic dataset built for research. While it doesn’t contain real people’s data, it mirrors patterns found in actual surveys — making it a safe and realistic starting point for exploring how lifestyle might relate to anxiety."
  },
  {
    "objectID": "index.html#what-the-data-looked-like",
    "href": "index.html#what-the-data-looked-like",
    "title": "Exploring the Link Between Lifestyle and Anxiety",
    "section": "What the Data Looked Like",
    "text": "What the Data Looked Like\nhe dataset included self-reported anxiety levels rated from 1 (very low) to 10 (very high), along with a range of lifestyle and behavioral traits. As shown in the chart below, most responses landed in the moderate range — with very high anxiety levels (8 to 10) relatively rare.\n\n\n\n\n\n\n\n\n\n\nKey Variables and Initial Trends\nWe focused on six variables that consistently showed relationships with anxiety:\n\nStress Level (1–10): Higher stress scores were often reported alongside higher anxiety — one of the clearest visual patterns in the data.\n\nTherapy Sessions (per month): People with moderate anxiety usually reported 0–2 sessions, while those with high anxiety more often reported 4–9 — forming two clear clusters.\n\nSleep Hours: Individuals with higher anxiety — especially at levels 8 to 10 — tended to report fewer hours of sleep.\n\nCaffeine Intake (mg/day): Anxiety tended to rise with caffeine, though the pattern wasn’t as steep as with stress or sleep.\n\nDiet Quality (1–10): No one with high anxiety rated their diet quality above a 5 — a sharp cutoff not seen in other groups.\n\nFamily History of Anxiety: This became more common as anxiety levels rose — from under 50% at the low end to over 75% at the high end.\n\nWhen we look at these variables side by side, a few patterns begin to emerge:\n\nHigher stress and caffeine are more common at higher anxiety levels.\n\nSleep and diet quality tend to drop as anxiety increases — especially at the high end.\n\nTherapy sessions show a split: low-to-moderate anxiety with minimal use, high anxiety with frequent sessions."
  },
  {
    "objectID": "index.html#a-two-part-strategy",
    "href": "index.html#a-two-part-strategy",
    "title": "Exploring the Link Between Lifestyle and Anxiety",
    "section": "A Two-Part Strategy",
    "text": "A Two-Part Strategy\nAnxiety scores at the high end of the scale (8–10) followed different patterns than the rest of the data. These cases were less common, more extreme, and didn’t align with the trends seen at lower levels.\nTrying to use a single model would have forced the data into patterns that didn’t fit — especially when it came to identifying people with the highest anxiety levels.\nTo address this, I used a two-part strategy:\n\nA binary model to flag individuals with high anxiety (levels 8–10).\n\nA second model to predict specific anxiety levels within the more moderate range (1–7).\n\nThis setup helped us model each group more effectively, without forcing a single approach to cover conflicting patterns."
  },
  {
    "objectID": "index.html#labeling-high-anxiety-levels-810",
    "href": "index.html#labeling-high-anxiety-levels-810",
    "title": "Exploring the Link Between Lifestyle and Anxiety",
    "section": "Labeling High Anxiety (Levels 8–10)",
    "text": "Labeling High Anxiety (Levels 8–10)"
  },
  {
    "objectID": "index.html#understanding-high-anxiety-levels-810",
    "href": "index.html#understanding-high-anxiety-levels-810",
    "title": "Exploring the Link Between Lifestyle and Anxiety",
    "section": "Understanding High Anxiety (Levels 8–10)",
    "text": "Understanding High Anxiety (Levels 8–10)\nTo explore what kinds of factors tend to separate high-anxiety (8–10) cases from others, I built a logistic regression model using five lifestyle variables that showed strong relationships in earlier analysis:\n\nStress level\n\nSleep hours\n\nCaffeine intake\n\nDiet quality\n\nTherapy sessions\n\nThe model estimates the log-odds of being in the high-anxiety group — a standard way of modeling relative risk. The equation below summarizes how each variable contributes. We’ll focus on the direction and relative size of each effect just after.\n\\[\n\\begin{align*}\n\\widehat{\\log\\left[\\text{Odds}_\\text{High Anxiety}\\right]} =\\ & -1.269 \\\\\n&+ 1.071\\ \\cdot\\ \\text{Therapy Sessions} \\\\\n&+ 0.865\\ \\cdot\\ \\text{Stress Level} \\\\\n&- 2.596\\ \\cdot\\ \\text{Sleep Hours} \\\\\n&+ 0.0106\\ \\cdot\\ \\text{Caffeine Intake} \\\\\n&- 0.556\\ \\cdot\\ \\text{Diet Quality}\n\\end{align*}\n\\]\nStress and sleep had the largest coefficients — suggesting stronger associations with high anxiety. Therapy sessions, diet, and caffeine played smaller but consistent roles. Let’s break those roles down:\n\nHigher stress levels were strongly linked to high anxiety — one of the clearest patterns in the data.\n\nMore sleep was tied to a lower likelihood of high anxiety. Even one extra hour made a noticeable difference.\n\nMore therapy sessions were associated with a higher predicted risk. This doesn’t mean therapy causes anxiety — more likely, people with higher anxiety are more likely to seek support.\n\nCaffeine intake had a small effect per milligram, but its cumulative impact was noticeable.\n\nHigher diet quality was associated with lower anxiety, though its effect was smaller than stress or sleep.\n\n\nDoes the Model Hold Up?\nTo make sure the model was actually picking up real patterns — and not just noise — I ran a few simple checks. These aren’t about pinpointing exact outcomes or predicting individuals. Instead, they help confirm that the model reflects structure in the data: that the relationships it found between anxiety and lifestyle factors show up consistently across the sample.\nBelow is the confusion matrix, which shows what happens if we use a 50% threshold: anyone with a predicted probability above 50% is labeled as “high anxiety.”\n\nOut of 1,014 individuals who actually had high anxiety, 44 were missed (false negatives).\n\n48 people were incorrectly flagged as high anxiety (false positives).\n\nIt’s not a perfect separation, but the results reflect a general alignment with the earlier patterns in the data.\n\n\n\n\n\n\n\n\n\n\n\nContextual Effects in Anxiety Patterns\nThe main model looks at each factor independently. But in practice, lifestyle traits don’t operate in isolation — they overlap, reinforce, and sometimes offset one another. To explore this, I examined how three key factors — sleep, diet, and therapy use — interacted with each other when estimating the likelihood of high anxiety.\nEach panel below shows how the relationship between one factor and anxiety shifts depending on levels of the other two. These aren’t predictions from the main model — they come from a follow-up model that includes interactions, allowing us to examine how the effects of one habit depend on the context of the others.\nA few patterns stood out:\n\nTherapy sessions were most strongly associated with high anxiety when both sleep and diet quality were low. But when both were strong, therapy use had little to no additional association with anxiety risk. This suggests therapy may be most common or most reactive in settings where other supports are lacking.\n\nSleep showed a more protective pattern when therapy use was high or diet was poor — possibly acting as a buffer when other conditions were less favorable.\n\nDiet quality displayed a less linear pattern. It seemed to buffer anxiety when sleep was low or therapy use was high, but the trend flattened — or even slightly reversed — when those other supports were already strong.\n\nThese effects weren’t included in the final model — keeping things simple and interpretable was the priority. But they help highlight a key point: the impact of any one behavior may shift depending on what else is happening. Context matters, and these interaction plots offer a more layered view of how anxiety and lifestyle habits relate in this dataset.\n\nTherapySleepDiet"
  },
  {
    "objectID": "index.html#understanding-moderate-anxiety-levels-17",
    "href": "index.html#understanding-moderate-anxiety-levels-17",
    "title": "Exploring the Link Between Lifestyle and Anxiety",
    "section": "Understanding Moderate Anxiety (Levels 1–7)",
    "text": "Understanding Moderate Anxiety (Levels 1–7)\nTo explore how different lifestyle traits relate to anxiety scores in the moderate range (1–7), I used a linear regression model. While these scores are ordinal rather than continuous, a linear model offers a simple and interpretable way to summarize how each factor tends to shift the outcome.\nThe equation below shows how each variable contributed to the model’s estimates:\n\\[\n\\begin{align*}\n\\widehat{\\text{Anxiety Level}} =\\ & 2.503 \\\\\n&+ 0.339\\ \\cdot\\ \\text{Stress Level} \\\\\n&- 0.230\\ \\cdot\\ \\text{Sleep Hours} \\\\\n&+ 0.0014\\ \\cdot\\ \\text{Caffeine Intake} \\\\\n&+ 0.0915\\ \\cdot\\ \\text{Therapy Sessions} \\\\\n&+ 0.116\\ \\cdot\\ \\text{Family History (Yes)}\n\\end{align*}\n\\]\nStress and sleep again had the strongest associations with anxiety scores. Therapy sessions, caffeine, and family history also contributed, but their effects were more modest.\n\nEach additional point on the stress scale raised the predicted anxiety level by about 0.34 points.\n\nEach extra hour of sleep lowered it by about 0.23 points.\n\nEach therapy session per month added around 0.09 points.\n\nCaffeine had a small effect per milligram — about 0.0014 points.\n\nHaving a family history of anxiety added about 0.12 points on average.\n\nThese individual shifts were small, but consistent. And taken together, they helped the model describe broad trends in how anxiety levels varied across the sample.\n\nDoes the Model Hold Up?\nAs shown in the confusion matrix below, most predictions clustered near the correct value — especially in the middle of the scale. That’s a reasonable result for a seven-point measure, where even human responses often blur the line between, say, a 4 and a 5. More specifically:\n\nIt predicted the exact anxiety level correctly 37.6% of the time.\n\nIt was within ±1 point of the true level 87.3% of the time.\n\nOn the other hand, the model struggled at the extremes, rarely predicting the lowest or highest scores. Considering we already flagged high risk individuals, this limitation is acceptable. Still, it’s a helpful reminder that this model is better suited for exploring overall trends than for making precise individual predictions."
  },
  {
    "objectID": "index.html#key-insights",
    "href": "index.html#key-insights",
    "title": "Exploring the Link Between Lifestyle and Anxiety",
    "section": "Key Insights",
    "text": "Key Insights\nWhile this is synthetic data, it mirrors real-world patterns — and a few key themes stood out:\n\nSleep and stress were the most consistently associated with anxiety levels. These patterns weren’t subtle: higher stress and less sleep closely tracked with higher anxiety, across both models and every part of the analysis. While that might feel intuitive, the consistency and strength of these links are worth noting. It’s a reminder that even simple, daily experiences can meaningfully align with how anxiety presents.\nTherapy use was strongly linked to high anxiety — likely as a response, not a cause. People attending more sessions were more likely to fall in the high-anxiety group. This likely reflects a reactive pattern: those in distress are more likely to seek help. In that way, therapy use became one of the most distinguishable signals in the model — not because it causes anxiety, but because it often accompanies it. It’s a good example of how responses to a condition can become some of its most visible markers.\nCaffeine showed a mild association with anxiety. There was a trend: more caffeine, more anxiety. But the effect was small and gradual — much weaker than stress or sleep — and may reflect other underlying factors like sleep quality or stress levels. This isn’t a warning against coffee, but a small nudge toward moderation and context.\nDiet quality revealed a sharp pattern at the high end of anxiety. In the high-anxiety group, no one rated their diet above a 5. That kind of cutoff didn’t show up elsewhere. While this might partly reflect the structure of the synthetic data, it raises questions about how self-perceived nutrition relates to mental health. That said, the effect wasn’t as strong in other models, so more research would be needed to know whether this is a real threshold or a coincidental artifact.\nFamily history mattered — but less than lifestyle. People with a family history of anxiety reported slightly higher levels overall, but the effect was smaller than that of habits like stress, sleep, or diet. It seems to act more like a background signal — relevant, but less decisive.\n\nPerhaps most importantly, no single factor explains anxiety on its own. The interaction models showed that the influence of one habit often depends on others — for example, therapy use was most predictive of high anxiety when both sleep and diet were poor. But when sleep and diet were strong, therapy use alone didn’t add much predictive power. This reinforces the idea that anxiety reflects not just individual behaviors, but the context in which they occur. These lifestyle traits don’t act in isolation — they reinforce, offset, or amplify one another, shaping anxiety as a system, not a checklist."
  },
  {
    "objectID": "index.html#conclusion",
    "href": "index.html#conclusion",
    "title": "Exploring the Link Between Lifestyle and Anxiety",
    "section": "Conclusion",
    "text": "Conclusion\nAnxiety is complex. It doesn’t arise from a single habit or trait — but it does leave patterns. This project used synthetic data to explore how everyday factors like sleep, diet, stress, and therapy use tend to align with different levels of anxiety.\nSome of these patterns were expected, like the close link between stress and anxiety. Others — like the conditional role of therapy use, or the sharp drop in diet quality among high-anxiety individuals — offered less familiar perspectives. These aren’t clinical conclusions, but they suggest possible avenues for deeper research.\nMore broadly, the analysis reinforced a key idea: context matters. The impact of one habit often depends on what else is happening. Sleep might help buffer stress. Therapy might be a strong signal in some situations but not others. These kinds of patterns only emerge when we look at combinations — not just averages.\nThis isn’t a final answer. It’s a starting point. It shows how even simple, interpretable models can help surface patterns in messy, human data. And it reminds us that statistical tools don’t need to be perfect to be useful — especially when they help us ask clearer questions, or think more carefully about how mental health shows up in real life."
  },
  {
    "objectID": "statistical_supplements/exploratory_data_analysis.html",
    "href": "statistical_supplements/exploratory_data_analysis.html",
    "title": "Exploratory Data Analysis of Anxiety and Predictors",
    "section": "",
    "text": "This exploratory data analysis examines how a range of behavioral, physiological, and demographic predictors relate to self-reported anxiety levels (1–10). The goal is to surface patterns, distributions, and potential structural distinctions that may guide future modeling decisions."
  },
  {
    "objectID": "statistical_supplements/exploratory_data_analysis.html#visualizations",
    "href": "statistical_supplements/exploratory_data_analysis.html#visualizations",
    "title": "Exploratory Data Analysis of Anxiety and Predictors",
    "section": "Visualizations",
    "text": "Visualizations\n\nSingle Variable Plots\nTo guide univariate visualizations, predictors were grouped into five structural types: Categorical (Few), Categorical (Many), Ordinal, Discrete, and Continuous. Visualizations were matched accordingly—e.g., bar plots for discrete or ordinal variables, and histograms with overlaid density curves for continuous ones (10 bins, adjust = 1.5) to smooth sampling artifacts without distorting shape. This approach balances visual clarity with representational accuracy.\nMost variables are roughly uniform or flat. Notable exceptions include Sleep Hours (approximately normal), Caffeine Intake (slightly left-skewed), and Physical Activity and Therapy Sessions (strongly right-skewed, which may hint towards log transformation when modeling). Anxiety Level, while also right-skewed, is treated as an ordinal response and shouldn’t be transformed.\nUse the dropdown below to explore each variable’s distribution and summary statistics interactively.\n\nAge\nGender\nOccupation\nSleep Hours\nPhysical Activity (hrs/week)\nCaffeine Intake (mg/day)\nAlcohol Consumption (drinks/week)\nSmoking\nFamily History of Anxiety\nStress Level (1-10)\nHeart Rate (bpm)\nBreathing Rate (breaths/min)\nSweating Level (1-5)\nDizziness\nMedication\nTherapy Sessions (per month)\nRecent Major Life Event\nDiet Quality (1-10)\nAnxiety Level (1-10)\n\n\n\nGender\n\n\n\nCounts:\n\n\n\nFemale\nMale\nOther\n\n\n\n\n3730\n3657\n3613\n\n\n\n\n\n\n\nSmoking\n\n\n\nCounts:\n\n\n\nNo\nYes\n\n\n\n\n5221\n5779\n\n\n\n\n\n\n\nFamily History of Anxiety\n\n\n\nCounts:\n\n\n\nNo\nYes\n\n\n\n\n5153\n5847\n\n\n\n\n\n\n\nDizziness\n\n\n\nCounts:\n\n\n\nNo\nYes\n\n\n\n\n5328\n5672\n\n\n\n\n\n\n\nMedication\n\n\n\nCounts:\n\n\n\nNo\nYes\n\n\n\n\n5334\n5666\n\n\n\n\n\n\n\nRecent Major Life Event\n\n\n\nCounts:\n\n\n\nNo\nYes\n\n\n\n\n5377\n5623\n\n\n\n\n\n\n\nOccupation\n\n\n\nCounts:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArtist\nAthlete\nChef\nDoctor\nEngineer\nFreelancer\nLawyer\nMusician\nNurse\nOther\nScientist\nStudent\nTeacher\n\n\n\n\n888\n822\n858\n842\n833\n838\n809\n892\n861\n840\n832\n878\n807\n\n\n\n\n\n\n\nStress Level (1-10)\n\n\n\nCounts:\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n\n978\n999\n964\n976\n1037\n998\n1006\n1326\n1335\n1381\n\n\n\n\n\n\n\nSweating Level (1-5)\n\n\n\nCounts:\n\n\n\n1\n2\n3\n4\n5\n\n\n\n\n1978\n2092\n2323\n2279\n2328\n\n\n\n\n\n\n\nDiet Quality (1-10)\n\n\n\nCounts:\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n\n1281\n1291\n1254\n1260\n994\n985\n991\n960\n1002\n982\n\n\n\n\n\n\n\nAnxiety Level (1-10)\n\n\n\nCounts:\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n\n1039\n1756\n2407\n2416\n1629\n616\n123\n363\n329\n322\n\n\n\n\n\n\n\nAlcohol Consumption (drinks/week)\n\n\n\nSummary Statistics: \n\n\n\nMean\nMedian\nSD\nSkewness\n\n\n\n\n9.702\n10\n5.69\n-0.023\n\n\n\n\n\n\n\nTherapy Sessions (per month)\n\n\n\nSummary Statistics: \n\n\n\nMean\nMedian\nSD\nSkewness\n\n\n\n\n2.428\n2\n2.183\n1.035\n\n\n\n\n\n\n\nBreathing Rate (breaths/min)\n\n\n\nSummary Statistics: \n\n\n\nMean\nMedian\nSD\nSkewness\n\n\n\n\n20.958\n21\n5.16\n-0.141\n\n\n\n\n\n\n\nAge\n\n\n\nSummary Statistics: \n\n\n\nMean\nMedian\nSD\nSkewness\n\n\n\n\n40.242\n40\n13.236\n0.097\n\n\n\n\n\n\n\nSleep Hours\n\n\n\nSummary Statistics: \n\n\n\nMean\nMedian\nSD\nSkewness\n\n\n\n\n6.651\n6.7\n1.228\n-0.224\n\n\n\n\n\n\n\nPhysical Activity (hrs/week)\n\n\n\nSummary Statistics: \n\n\n\nMean\nMedian\nSD\nSkewness\n\n\n\n\n2.942\n2.8\n1.828\n0.507\n\n\n\n\n\n\n\nCaffeine Intake (mg/day)\n\n\n\nSummary Statistics: \n\n\n\nMean\nMedian\nSD\nSkewness\n\n\n\n\n286.09\n273\n144.813\n0.324\n\n\n\n\n\n\n\nHeart Rate (bpm)\n\n\n\nSummary Statistics: \n\n\n\nMean\nMedian\nSD\nSkewness\n\n\n\n\n90.916\n92\n17.326\n-0.119\n\n\n\n\n\n\n\nAnxiety Level vs Other Variable Plots\nTo explore how each variable relates to the response variable Anxiety Level (1–10), we selected visualization strategies matched to variable type. While ordinal, Anxiety Level can flexibly be treated as categorical or numeric depending on context. For example, heatmaps were used for ordinal/discrete pairs, while continuous predictors were paired with boxplots, and categorical variables with bar or density plots. These choices maximize interpretability, particularly given the discrete nature of anxiety ratings.\nUse the dropdown below to explore each variable’s distribution and summary statistics interactively.\n\nAge\nGender\nOccupation\nSleep Hours\nPhysical Activity (hrs/week)\nCaffeine Intake (mg/day)\nAlcohol Consumption (drinks/week)\nSmoking\nFamily History of Anxiety\nStress Level (1-10)\nHeart Rate (bpm)\nBreathing Rate (breaths/min)\nSweating Level (1-5)\nDizziness\nMedication\nTherapy Sessions (per month)\nRecent Major Life Event\nDiet Quality (1-10)\n\n\n\n\nAnxiety Level (1-10) vs Gender\n\n\n\n\n\n\n\nAnxiety Level (1-10) vs Smoking\n\n\n\n\n\n\n\nAnxiety Level (1-10) vs Family History of Anxiety\n\n\n\n\n\n\n\nAnxiety Level (1-10) vs Dizziness\n\n\n\n\n\n\n\nAnxiety Level (1-10) vs Medication\n\n\n\n\n\n\n\nAnxiety Level (1-10) vs Recent Major Life Event\n\n\n\n\n\n\n\nAnxiety Level (1-10) vs Occupation\n\n\n\n\n\n\n\nAnxiety Level (1-10) vs Stress Level (1-10)\n\n\n\n\n\n\n\nAnxiety Level (1-10) vs Sweating Level (1-5)\n\n\n\n\n\n\n\nAnxiety Level (1-10) vs Diet Quality (1-10)\n\n\n\n\n\n\n\nAnxiety Level (1-10) vs Alcohol Consumption (drinks/week)\n\n\n\n\n\n\n\nAnxiety Level (1-10) vs Therapy Sessions (per month)\n\n\n\n\n\n\n\nAnxiety Level (1-10) vs Breathing Rate (breaths/min)\n\n\n\n\n\n\n\nAnxiety Level (1-10) vs Age\n\n\n\n\n\n\n\nAnxiety Level (1-10) vs Sleep Hours\n\n\n\n\n\n\n\nAnxiety Level (1-10) vs Physical Activity (hrs/week)\n\n\n\n\n\n\n\nAnxiety Level (1-10) vs Caffeine Intake (mg/day)\n\n\n\n\n\n\n\nAnxiety Level (1-10) vs Heart Rate (bpm)\n\n\n\n\n\nThe visualizations suggest that anxiety levels 8–10 may form a distinct subgroup. Across many variables, these levels appear to behave differently from levels 1–7. We summarize the key differences below.\n\nCategorical Variables\n\nGender, Smoking, Dizziness, Medication, and Recent Major Life Event display internally consistent distributions within levels 1–7 and within 8–10 — but the proportions differ markedly between these two ranges.\nFamily History of Anxiety shows a clear increasing trend with Anxiety Level, which plateaus at higher levels.\nOccupation appears to have minimal association with anxiety — inter-group distributions are largely overlapping.\n\n\n\nNumeric and Ordinal Variables\n\nAge, Sleep Hours, Physical Activity, and Heart Rate show relatively stable averages within levels 1–7, then shift to consistently different values for levels 8–10 — again supporting a two-regime structure.\nCaffeine Intake increases with anxiety level but levels off at the top three — similar to the Family History trend.\nStress Level increases steadily with anxiety through level 6, has sparse data at level 7, and becomes uniformly high in the top three.\nTherapy Sessions follows a bimodal distribution with respect to anxiety. The lower anxiety group (1–7) is characterized by an approximately a concentrated cluster around low session counts (≈1/month), while levels 8–10 show a broader, less structured spread across session counts from 4 to 9. This separation suggests two distinct behavioral regimes — one centered and structured, the other elevated and diffuse.\nAlcohol Consumption, Breathing Rate, Sweating Level, and Diet Quality don’t show clear trends across the full scale but stand out for a different reason: none of the participants at levels 8–10 fall into the “healthy” range for these variables.\n\n\n\n\nModeling Implications\nThe analysis suggests a clear divide in how predictors relate to Anxiety Level: responses in the 8–10 range show different patterns than those in the 1–7 range across many variables. These differences are substantial enough to warrant treating the groups separately in modeling.\nTo address this, we adopt a stacked modeling strategy:\n\nA logistic model first distinguishes between Low / Moderate Anxiety (levels 1–7) and High Anxiety (levels 8–10).\nThen, two separate models are used:\n\nOne to predict specific anxiety levels within the Low / Moderate group.\nAnother trained only on the High Anxiety group.\n\n\nThis setup allows each model to focus on patterns that are internally consistent within its group, rather than forcing a single model to bridge competing dynamics. While this approach introduces additional complexity, it offers gains in both interpretability and performance. The specific challenges and decisions for each stage will be addressed in the modeling sections that follow."
  },
  {
    "objectID": "statistical_supplements/low-mod_vs_high_logisitc.html",
    "href": "statistical_supplements/low-mod_vs_high_logisitc.html",
    "title": "Predicting Low / Moderate vs High Anxiety",
    "section": "",
    "text": "As our primary modeling goal is interpretation, logistic regression is a natural choice. It offers a balance between statistical rigor and interpretability, allowing us to quantify the direction and strength of associations between predictors and the probability of high anxiety.\nOur exploratory data analysis revealed distinct behavioral patterns between the two outcome groups — Low/Moderate Anxiety vs High Anxiety — suggesting that a logistic regression model should be capable of capturing meaningful signal from the predictors.\nBefore fitting the model, we assessed the distribution of the binary outcome. The result indicated a substantial class imbalance, with approximately a 10:1 ratio favoring the Low/Moderate Anxiety group. Despite this, the minority class (High Anxiety) includes over 1,000 observations — a sufficient sample size for modeling, especially given our focus on estimation rather than classification performance.\n\n\n\nLow/Moderate Anxiety         High Anxiety \n                9986                 1014 \n\n\nWhile class imbalance often warrants consideration of remedies such as class weighting or resampling (e.g., SMOTE, undersampling), these approaches come with notable trade-offs. Weighted models complicate coefficient interpretation by altering the meaning of the estimated log-odds, while resampling distorts the natural prevalence of the outcome — a key feature when the goal is to understand real-world data as it is, not as it might be under synthetic balance.\nBecause our objective is to understand the relationship between predictors and the likelihood of high anxiety in the real population, we deliberately avoid rebalancing techniques. Instead, we proceed with a standard logistic regression model, relying on its capacity to yield interpretable and statistically sound insights, even in the presence of imbalance."
  },
  {
    "objectID": "statistical_supplements/low-mod_vs_high_logisitc.html#overview",
    "href": "statistical_supplements/low-mod_vs_high_logisitc.html#overview",
    "title": "Predicting Low / Moderate vs High Anxiety",
    "section": "",
    "text": "As our primary modeling goal is interpretation, logistic regression is a natural choice. It offers a balance between statistical rigor and interpretability, allowing us to quantify the direction and strength of associations between predictors and the probability of high anxiety.\nOur exploratory data analysis revealed distinct behavioral patterns between the two outcome groups — Low/Moderate Anxiety vs High Anxiety — suggesting that a logistic regression model should be capable of capturing meaningful signal from the predictors.\nBefore fitting the model, we assessed the distribution of the binary outcome. The result indicated a substantial class imbalance, with approximately a 10:1 ratio favoring the Low/Moderate Anxiety group. Despite this, the minority class (High Anxiety) includes over 1,000 observations — a sufficient sample size for modeling, especially given our focus on estimation rather than classification performance.\n\n\n\nLow/Moderate Anxiety         High Anxiety \n                9986                 1014 \n\n\nWhile class imbalance often warrants consideration of remedies such as class weighting or resampling (e.g., SMOTE, undersampling), these approaches come with notable trade-offs. Weighted models complicate coefficient interpretation by altering the meaning of the estimated log-odds, while resampling distorts the natural prevalence of the outcome — a key feature when the goal is to understand real-world data as it is, not as it might be under synthetic balance.\nBecause our objective is to understand the relationship between predictors and the likelihood of high anxiety in the real population, we deliberately avoid rebalancing techniques. Instead, we proceed with a standard logistic regression model, relying on its capacity to yield interpretable and statistically sound insights, even in the presence of imbalance."
  },
  {
    "objectID": "statistical_supplements/low-mod_vs_high_logisitc.html#model-selection",
    "href": "statistical_supplements/low-mod_vs_high_logisitc.html#model-selection",
    "title": "Predicting Low / Moderate vs High Anxiety",
    "section": "Model Selection",
    "text": "Model Selection\n\nParsimonious, Importance-Driven Model\nWe computed permutation-based feature importance using a random forest. A clear inflection point in the importance rankings suggests that the top five variables—Therapy Sessions, Stress Level, Sleep Hours, Caffeine Intake, and Diet Quality—form a distinct group, contributing substantially more predictive information than the remaining features. This observation, paired with the common rule-of-thumb of limiting logistic models to ~5 predictors to avoid overfitting, motivated our choice to begin with this compact set.\n\n\n\n\n\n\n\n\n\nWhile additional variables may be considered later, this starting point balances statistical rigor, model stability, and interpretability. All subsequent decisions are guided by model comparison statistics and the overarching goal of building a transparent and communicable model.\n\n\nAnxietyBinary ~ Therapy.Sessions + Stress.Level + Sleep.Hours + \n    Caffeine.Intake + Diet.Quality\n\n\n\nRemoving VariablesAdding VariablesStep-wise Selection\n\n\nTo test whether each predictor in the initial model contributes meaningfully to model fit, we conducted a series of single-variable removal tests. For each test, a simplified model was created by dropping one predictor, then compared to the five-variable model using AIC, BIC, and Bayes Factors. This approach helps identify variables that may be redundant or contribute minimal added value relative to the model’s complexity.\nThe results (shown below) indicate that removing any one of the five predictors leads to a notably worse-fitting model across all criteria. In each case, BIC increases and the corresponding Bayes Factor favors the full model, suggesting that each variable provides unique explanatory signal. These findings support retaining all five predictors in the base model.\n\n\nTherapy Sessions:\n\n\n                      aic      bic  bayes.factor      p\nsimplified_model 1155.404 1191.933  0.000000e+00 &lt;2e-16\ninitial_model     581.382  625.216 1.150797e+123       \n\n\nStress Level:\n\n\n                     aic     bic bayes.factor      p\nsimplified_model 824.232 860.760 0.000000e+00 &lt;2e-16\ninitial_model    581.382 625.216 1.405521e+51       \n\n\nSleep Hours:\n\n\n                      aic      bic  bayes.factor      p\nsimplified_model 1287.966 1324.494  0.000000e+00 &lt;2e-16\ninitial_model     581.382  625.216 7.019365e+151       \n\n\nCaffeine Intake:\n\n\n                     aic     bic bayes.factor      p\nsimplified_model 720.781 757.309 0.000000e+00 &lt;2e-16\ninitial_model    581.382 625.216 4.826904e+28       \n\n\nDiet Quality:\n\n\n                     aic     bic bayes.factor      p\nsimplified_model 704.694 741.222 0.000000e+00 &lt;2e-16\ninitial_model    581.382 625.216 1.550702e+25       \n\n\n\n\nWe next tested whether additional predictors, ranked by permutation importance, meaningfully improved model fit. Each was tentatively added in sequence, with comparisons based on AIC, BIC, and Bayes Factors.\nHeart Rate, Sweating Level, Breathing Rate, Physical Activity, and Age all improved fit and were retained. Alcohol Consumption did not—BIC increased, and the Bayes Factor favored the simpler model—so no further variables were added.\nThe resulting model includes all predictors supported by importance rankings and model comparison statistics, without incorporating variables of negligible value.\n\nHeart Rate\n\n\n                     aic     bic bayes.factor      p\nno_heart_rate    581.382 625.216            0 &lt;2e-16\nheart_rate_added 536.020 587.160    183547794       \n\n\n                     aic    bic bayes.factor      p\nheart_rate_added 536.020 587.16            0 &lt;2e-16\nsweating_added   492.385 550.83     77427673       \n\n\n                    aic     bic bayes.factor      p\nsweating_added  492.385 550.830        0.008 &lt;2e-16\nbreathing_added 475.327 541.078      131.140       \n\n\n                    aic     bic bayes.factor      p\nbreathing_added 475.327 541.078 0.000000e+00 &lt;2e-16\nactivity_added  381.729 454.786 5.470769e+18       \n\n\n                   aic     bic bayes.factor      p\nactivity_added 381.729 454.786        0.006 &lt;2e-16\nage_added      364.269 444.631      160.329       \n\n\n                  aic     bic bayes.factor     p\nage_added     364.269 444.631       31.559 0.121\nalcohol_added 363.867 451.535        0.032      \n\n\nAnxietyBinary ~ Therapy.Sessions + Stress.Level + Sleep.Hours + \n    Caffeine.Intake + Diet.Quality + Heart.Rate + Sweating.Level + \n    Breathing.Rate + Physical.Activity + Age\n\n\n\n\n\nTo compare our manual approach against a traditional model selection method, we ran a stepwise selection procedure using AIC. The process began with the initial five-variable model and evaluated additions and removals based on AIC improvements.\n\n\nAnxietyBinary ~ Therapy.Sessions + Stress.Level + Sleep.Hours + \n    Caffeine.Intake + Diet.Quality + Physical.Activity + Sweating.Level + \n    Heart.Rate + Age + Breathing.Rate + Alcohol.Consumption\n\n\nThe stepwise procedure yielded a model nearly identical to the one selected manually—differing only by the inclusion of Alcohol Consumption, which our manual process excluded due to weaker model comparison support. This convergence supports the robustness of the manually selected model.\n\n\n\n\n\nSelecting a Model\nTo compare candidate models, we evaluated their discriminative performance using the Area Under the ROC Curve (AUC). AUC offers a single, interpretable measure of how well a model distinguishes between high and low/moderate anxiety cases, and is a pragmatic way to navigate model decision overload when all candidates appear strong. In our analysis, every model — from the initial five-variable additive model to the fully extended version — achieved AUCs exceeding 0.998.\nThis uniformly high performance presented a practical dilemma: when every model performs exceptionally, how do we choose?\n\n\n\n\n\n\nWhile AUC differences were numerically small (e.g., +0.0005 from importance-based five-variable model to full model with all variables), they underscore a broader tradeoff. The models offering slight performance gains did so at the cost of complexity and interpretability. AUC does not reflect:\n\nCalibration — whether predicted probabilities match actual outcomes.\nLocal fit — whether the model performs equally well across different subgroups.\nExplanatory clarity — whether stakeholders can make sense of the results.\n\nWe used AUC as a pragmatic filter, not a final arbiter. Its role was to flag when a model’s added complexity didn’t meaningfully improve performance, so we could focus on models that were both accurate and communicable. As such, we selected the importance-guided five-variable model for its balance of clarity and explanatory power — simple enough to interpret easily, yet robust enough to capture the key signals in the data."
  },
  {
    "objectID": "statistical_supplements/low-mod_vs_high_logisitc.html#diagnostics",
    "href": "statistical_supplements/low-mod_vs_high_logisitc.html#diagnostics",
    "title": "Predicting Low / Moderate vs High Anxiety",
    "section": "Diagnostics",
    "text": "Diagnostics\nWith our model selected, we now assess its diagnostics to ensure the assumptions of logistic regression are reasonably satisfied and that the results are stable and interpretable. This section is organized around three core pillars of diagnostic evaluation:\n\nOutlier analysis, which helps identify individual observations that may unduly influence model estimates or mask broader patterns.\nStructural assumption checks, including linearity, additivity (no interaction terms), and multicollinearity, which apply on the logit scale and ensure the model’s functional form remains appropriate.\nCalibration assessment, which verifies that predicted probabilities align with observed outcome frequencies and that the model performs as a reliable estimator.\n\n\nOutlier Detection\nGiven the large sample size (~11,000 observations), the presence of outliers is statistically expected. However, certain outliers can have a disproportionate impact on model interpretation and parameter estimates.\n\nPlotsSystematic Outlier SelectionModeling Trimmed vs. Full Dataset\n\n\nTo explore this possibility, we generated four diagnostic plots aimed at visually identifying potentially problematic points.\nThe four plots include:\n\nLeverage vs. Cook’s Distance — highlights points that are both extreme in predictor space and exert strong global influence.\nLinear Predictor vs. Pearson Residuals — assesses model fit and potential non-linearity across the logit scale.\nLeverage vs. Pearson Residuals — identifies poorly fitted observations that may reside in sparse regions of the predictor space.\nCook’s Distance by Observation Index — detects globally influential observations without reference to specific predictors.\n\nNote: Labels were added heuristically, prioritizing points with the most extreme values while minimizing overlap to preserve readability. These labels are illustrative and do not represent an exhaustive set of outliers.\n\n\n\n\n\n\n\n\n\nWe highlight two key groups:\n\nPoints 10306, 2112, and 3963 These cases have large Pearson residuals but low leverage—meaning they aren’t unusual in terms of predictor values but are still mispredicted. All were labeled as “Low/Moderate Anxiety” but predicted as “High Anxiety,” likely due to high stress levels (9–10) and low therapy engagement (0–3 sessions/month). These seem like plausible edge cases, not data errors.\nPoints 10699, 6037, and 4214 These cases have high leverage and high Cook’s Distance but low residuals—suggesting that, despite being in sparse regions of the predictor space, the model predicted them reasonably well. Their predicted probabilities hover near the decision threshold (0.29 for 6037 and 0.5 for 10699 and 4214), which reflects some model uncertainty and aligns with their unusual combinations of predictors.\n\n\n\nWhile manual inspection is helpful, it’s not feasible to review every flagged case. Instead, we systematically selected the top 30 observations using the following criteria:\n\nAbsolute Pearson residual &gt; 2\nCook’s Distance &gt; 4 / n\nRanked by Cook’s Distance, prioritizing the most influential cases\n\n\n\n\n\n\n\nThese 30 observations were reviewed for unusual predictor combinations. Some notable patterns included:\n\nHigh anxiety despite good diet quality and/or low caffeine intake\nHigh stress levels paired with low anxiety\n\nWhile these combinations are rare, they’re not implausible. Excluding them would risk modeling an oversimplified—and potentially biased—version of reality that ignores meaningful edge cases.\n\n\nTo evaluate the impact of these outliers, we fit a trimmed model that excludes the top 30 most influential observations identified in the previous step.\n\n\n                             Term  Full_Model Trimmed_Model      Ratio\n(Intercept)           (Intercept) -1.26910159    0.14336484 -0.1129656\nTherapy.Sessions Therapy.Sessions  1.07122435    1.71925991  1.6049485\nStress.Level         Stress.Level  0.86483626    1.15320397  1.3334362\nSleep.Hours           Sleep.Hours -2.59648631   -4.12710413  1.5894958\nCaffeine.Intake   Caffeine.Intake  0.01058238    0.01643301  1.5528658\nDiet.Quality         Diet.Quality -0.55648236   -0.89431778  1.6070910\n\n\nModel trained with Full Data:  0.998  AUC\n\n\nModel trained with Trimmed Data:  0.9997 AUC (Trimmed Dataset)\n\n\nModel trained with Trimmed Data:  0.9979 AUC (Full Dataset)\n\n\nThe trimmed model preserves the direction of all coefficients, but their magnitudes increase by roughly 1.5×, consistent with the model being fit on less variable data. In linear regression, this kind of inflation might suggest overfitting or instability. In logistic regression, though, it typically reflects increased confidence in predictions rather than a meaningful gain in accuracy.\nIn terms of predictive performance, the difference is negligible. The trimmed model performs nearly perfectly on the reduced dataset—but that’s expected and uninformative, since the most influential points were removed. When evaluated on the full dataset—a more honest test—its AUC drops by just 0.0001. This suggests that, while the trimmed model has more extreme coefficients, it doesn’t improve performance and may even generalize slightly worse.\nGiven our goal of modeling real-world data, we choose to retain the model trained on the full dataset. It better captures natural variability and avoids excluding rare but plausible observations that might otherwise be misrepresented or lost.\n\n\n\n\n\nLinearity\nThe linearity plots show slight “S-shaped” curves for Diet Quality, Caffeine Intake, and Stress Level, suggesting mild nonlinearity near the extremes. These deviations appear subtle and are unlikely to meaningfully affect model performance. In contrast, Therapy Sessions and Sleep Hours show more pronounced curvature at higher log-odds, indicating a clearer violation of the linearity assumption. Interestingly, both exhibit patterns that resemble bimodal behavior, which may suggest that the model is underestimating their effects—possibly due to hidden structure or interaction effects. Rather than applying transformations prematurely, we next examine the additivity assumption to see whether interactions might explain these patterns.\n\n\n\n\n\n\n\n\n\n\n\nAdditivity\n\nIdentifying 2-way interactionsAdditive vs. Interaction ModelInteraction Plots\n\n\nTo test whether any interaction terms improve model fit, we use a likelihood ratio test comparing the additive model to one with all 2-way interactions. This is preferable to AIC or BIC here, since a few strong interactions could be obscured by others that slightly worsen fit. The LRT directly tests whether any interaction term adds value overall.\nThe likelihood ratio test shows that at least one interaction significantly improves model fit (p &lt; 0.001), suggesting a violation of the additivity assumption and supporting the presence of interaction effects.\n\n\nAnalysis of Deviance Table\n\nModel 1: AnxietyBinary ~ Sleep.Hours + Therapy.Sessions + Diet.Quality + \n    Stress.Level + Caffeine.Intake\nModel 2: AnxietyBinary ~ (Sleep.Hours + Therapy.Sessions + Diet.Quality + \n    Stress.Level + Caffeine.Intake)^2\n  Resid. Df Resid. Dev Df Deviance  Pr(&gt;Chi)    \n1     10994     569.38                          \n2     10984     518.88 10   50.503 2.156e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nNow that we know interaction terms collectively improve model fit, we use information criteria (AIC, BIC, and Bayes Factors) to identify which specific 2-way interactions are most supported. This shifts our focus from formal testing to model selection, prioritizing parsimony and interpretability.\n\n\n\n\n\n\nWhile some interaction models showed moderate Bayes Factors (e.g., BF ≈ 5) and small BIC improvements (ΔBIC &lt; 4), these results should be interpreted with caution given the large sample size (~11,000). At this scale, even minor departures from additivity can appear statistically significant without providing meaningful gains in interpretability or explanatory value.\nStill, while each interaction term shows only modest support on its own, their combined effect may be more substantial. Notably, interactions between Therapy Sessions and Diet Quality, Sleep Hours and Therapy Sessions, and Sleep Hours and Diet Quality each showed mild support when tested individually.\nThe three selected interaction terms form a natural set, suggesting that together they may capture a more coherent structure in the data. To evaluate this, let’s fit a model including all three pairwise interactions.\n\n\nThe interaction model is statistically superior by several criteria. Compared to the additive model, it improves fit substantially with ΔBIC = 14 and Bayes Factor ≈ 990. This is strong evidence that interaction terms — such as between Sleep Hours and Therapy Sessions, or Diet Quality and Sleep — explain meaningful variance in anxiety risk.\n\n\n                      aic     bic bayes.factor      p\nadditive_model    581.382 625.216        0.001 &lt;2e-16\ninteraction_model 545.670 611.421      989.776       \n\n\nHowever, our primary aim is not to build a perfect predictor. Instead, we seek a model that is:\n\nClear enough to communicate results to a broad audience,\nParsimonious enough to remain stable and generalizable, and\nTransparent enough to identify key relationships.\n\nThe additive model is deliberately oversimplified. It ignores subtle but real interdependencies between predictors. As a result, it cannot capture context-dependent effects — for instance, how the impact of poor diet might vary depending on sleep quality or therapy engagement.\nDespite these limitations, the additive model has advantages:\n\nIts structure is straightforward, allowing direct interpretation of individual predictors.\nIt facilitates communication with stakeholders unfamiliar with nonlinear or interaction-heavy models.\nIts predictions are nearly as accurate (AUC 0.9980 vs 0.9985) despite being simpler.\n\n\n\nAdditive model AUC:     0.998 \n\n\nInteraction model AUC:  0.9985 \n\n\nTo address this tradeoff, we retain the additive model for our primary analysis, while:\n\nExploring key interactions in a supplementary section, and\nEncouraging future work to consider more complex models where interpretability is not paramount.\n\nIn short: this model is not a perfect mirror of the data — but it’s a deliberately polished lens, tuned to clarify rather than to capture every nuance.\n\n\nAlthough we ultimately favored the additive model for its simplicity and interpretability, visualizing the interactions still reveals meaningful structure that may inform future research or support domain understanding.\n\nSleep Hours consistently exhibits a negative association with log-odds of high anxiety. This negative slope becomes more pronounced when both Therapy Sessions and Diet Quality are low, suggesting that adequate sleep is especially protective in less supportive therapeutic and nutritional contexts.\n\n\n\n\n\n\n\n\n\n\n\nTherapy Sessions typically show a mild positive slope, but this flattens or reverses (to slightly negative) under conditions of high Diet Quality and sufficient Sleep, implying that therapy’s marginal contribution may diminish when other protective factors are present.\n\n\n\n\n\n\n\n\n\n\n\nDiet Quality demonstrates context-dependent directionality: its slope is positive when Sleep is high and Therapy is low, but negative when Therapy is high and Sleep is low. This may point to a compensatory dynamic: when sleep or therapy are lacking, diet becomes more predictive, but when both are already sufficient, its marginal effect lessens—or even reverses.\n\n\n\n\n\n\n\n\n\n\nWhile these patterns aren’t strong enough to justify including interaction terms for performance, they may reflect underlying compensatory or synergistic effects between lifestyle variables. Visualizing these slopes adds interpretive nuance and may highlight thresholds or diminishing returns that are relevant for clinical or behavioral intervention.\n\n\n\n\n\nNo Multicollinearity\nAll predictors in the model have Variance Inflation Factors (VIFs) below 1.5—well under the common threshold of 5. This suggests that multicollinearity is not a concern, and that the predictors are sufficiently independent to yield stable, interpretable coefficients.\n\n\nVariance Inflation Factors:\n\n\nTherapy.Sessions     Stress.Level      Sleep.Hours  Caffeine.Intake \n        1.260667         1.087368         1.225833         1.100429 \n    Diet.Quality \n        1.089014 \n\n\n\n\nModel Calibration\nFor a logistic regression model to be interpretable, its predicted probabilities must be well-calibrated—that is, a 90% prediction should correspond to the event occurring about 90% of the time. In a well-calibrated model, predicted probabilities closely track observed event rates across the range of predictions.\nThe following two plots visualize this calibration in complementary ways:\n\nFine-Grained Calibration Plot (200 quantile bins): Predictions are grouped into 200 equally sized bins. The closer each point falls to the diagonal line, the better the alignment between predicted and observed frequencies. Deviations indicate areas of under- or over-confidence.\nCoarse Calibration Plot (5% fixed bins): Predictions are grouped into 5% intervals. Each point is labeled with its bin size, offering insight into the stability of the observed rates—smaller bins are more sensitive to noise.\n\n\n\n\n\n\n\n\n\n\nOverall, the model’s predicted probabilities align closely with observed event rates—most points lie near the diagonal line, suggesting strong calibration. In the fine-grained plot, we see dense clusters near (0, 0) and (1, 1), and fewer points in the middle. This reflects a confident model: most predictions are close to 0 or 1, with few uncertain cases near 0.5. The coarser plot confirms this pattern and adds bin sizes, making it easier to assess the reliability of each point\nA few notable patterns emerge:\n\nBins with small sample sizes (e.g., 9, 16, 18) show more deviation from the diagonal, likely due to sampling variability.\nSeveral mid-range points lie slightly above the line, indicating the model tends to underestimate the probability of high anxiety in those regions.\nIn the low-probability region near (0, 0), the observed event rate is even lower than predicted, suggesting the model slightly overestimates risk in that range.\n\nNone of these deviations appear especially concerning—overall, the model’s predicted probabilities track observed rates well, supporting good calibration.\n\n\nFinal Model Summary\nDiagnostic analyses indicate that the final logistic regression model is well-calibrated, interpretable, and robust to influential observations. Residual and outlier assessments revealed a small number of plausible edge cases with minimal impact on model stability. Linearity and additivity assumptions were largely satisfied, and while several interaction terms showed mild support, their inclusion yielded negligible gains in either performance or clarity. Calibration plots confirmed strong agreement between predicted and observed probabilities.\nThese results confirm that the model is well-suited for explanatory use — offering a stable, interpretable, and empirically justified foundation for communication and insight."
  },
  {
    "objectID": "statistical_supplements/low-mod_vs_high_logisitc.html#interpreting-the-final-model",
    "href": "statistical_supplements/low-mod_vs_high_logisitc.html#interpreting-the-final-model",
    "title": "Predicting Low / Moderate vs High Anxiety",
    "section": "Interpreting the Final Model",
    "text": "Interpreting the Final Model\n\nPredictor Effects\nNow that we’re confident in the quality of our model, let’s take a closer look at the logistic regression equation in terms of log-odds:\n\n\n\nCall:\nglm(formula = AnxietyBinary ~ Therapy.Sessions + Stress.Level + \n    Sleep.Hours + Caffeine.Intake + Diet.Quality, family = binomial(), \n    data = model_data)\n\nCoefficients:\n                  Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)      -1.269102   1.078253  -1.177    0.239    \nTherapy.Sessions  1.071224   0.067108  15.963   &lt;2e-16 ***\nStress.Level      0.864836   0.086795   9.964   &lt;2e-16 ***\nSleep.Hours      -2.596486   0.163356 -15.895   &lt;2e-16 ***\nCaffeine.Intake   0.010582   0.001045  10.123   &lt;2e-16 ***\nDiet.Quality     -0.556482   0.060275  -9.232   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 6766.25  on 10999  degrees of freedom\nResidual deviance:  569.38  on 10994  degrees of freedom\nAIC: 581.38\n\nNumber of Fisher Scoring iterations: 10\n\n\nWe can express the model as:\n\\[\n\\begin{align*}\n\\widehat{\\log\\left[\\frac{P(\\text{Anxiety} = \\text{High Anxiety})}{1 - P(\\text{Anxiety} = \\text{High Anxiety})}\\right]} =\\ & -1.269 \\\\\n&+ 1.071\\ \\cdot\\ \\text{Therapy Sessions} \\\\\n&+ 0.865\\ \\cdot\\ \\text{Stress Level} \\\\\n&- 2.596\\ \\cdot\\ \\text{Sleep Hours} \\\\\n&+ 0.0106\\ \\cdot\\ \\text{Caffeine Intake} \\\\\n&- 0.556\\ \\cdot\\ \\text{Diet Quality}\n\\end{align*}\n\\]\nLet’s break down what each predictor means in terms of odds:\n\nEach additional therapy session increases the odds by a factor of ×2.92, holding all other variables constant.\nEach additional stress level increases the odds by a factor of ×2.37, holding all other variables constant.\nEach additional hour of sleep decreases the odds by a factor of ×0.075 (or roughly ÷13.4), holding all other variables constant.\nEach extra milligram of caffeine increases the odds slightly (×1.011). But people usually consume caffeine in cups of coffee (≈100 mg), so let’s adjust the scale into cups (100 mg). Then, one extra cup increases the odds by a factor of ×2.88 (holding all other variables constant) — a much more meaningful change.\nFinally, an extra level of Diet Quality decreases the odds by a factor of ×0.573, holding all other variables constant.\n\n\n\nProbability Perspective\nWhile interpreting probabilities algebraically becomes more convoluted, we can still express the model in probabilistic form using the logistic (sigmoid) transformation: \\[\n\\widehat{P(\\text{Anxiety} = \\text{High Anxiety})} =\n\\dfrac{1}{1 + e^{-\\left(\n-1.269\n+ 1.071\\cdot\\text{Therapy Sessions}\n+ 0.865\\cdot\\text{Stress Level}\n- 2.596\\cdot\\text{Sleep Hours}\n+ 0.0106\\cdot\\text{Caffeine Intake}\n- 0.556\\cdot\\text{Diet Quality}\n\\right)}}\n\\]\nThis sigmoid structure transforms a linear combination of predictors into a predicted probability between 0 and 1. However, when multiple predictors are involved, interpreting this formula — or visualizing individual effects — becomes substantially more complex. Predicted probabilities depend on the full combination of input values, meaning that visualizations can only capture local, conditional effects, not generalizable insights.\nFor this reason, we focus on interpreting the odds ratios, which offer a clearer and more direct understanding of each predictor’s influence, independent of arbitrary baselines. These effects — such as a 13-fold decrease in odds for each additional hour of sleep, or a near tripling of odds per extra therapy session — provide a strong and interpretable summary of the model’s core insights.\nIn summary, while logistic regression does support probabilistic interpretation, odds-based analysis offers the most accessible and robust framing for the purposes of this analysis."
  },
  {
    "objectID": "statistical_supplements/low-mod_vs_high_logisitc.html#conclusion",
    "href": "statistical_supplements/low-mod_vs_high_logisitc.html#conclusion",
    "title": "Predicting Low / Moderate vs High Anxiety",
    "section": "Conclusion",
    "text": "Conclusion\nThis analysis set out to understand the factors most strongly associated with high anxiety. Using logistic regression, we developed a model that balances strong statistical performance with interpretive clarity — making it well-suited for transparent reporting and structured analysis of variable relationships.\nWhile more complex models with interaction terms yielded modest improvements in fit, they introduced interpretive overhead. We therefore retained a simpler additive model, allowing for straightforward, stable insights. To enrich this view, we analyzed and visualized key interactions separately — highlighting conditional patterns that inform, but do not complicate, the core structure.\nDiagnostic checks confirmed that the model is well-calibrated, resilient to outliers, and broadly stable. Though simplified by design, it offers a clear and defensible account of how behavioral and lifestyle factors relate to anxiety — and where deeper complexity begins to emerge."
  }
]