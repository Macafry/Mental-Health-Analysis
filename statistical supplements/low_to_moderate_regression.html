<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.549">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Ian McFarlane">

<title>Predicting across Low / Moderate Axniety Levels</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="low_to_moderate_regression_files/libs/clipboard/clipboard.min.js"></script>
<script src="low_to_moderate_regression_files/libs/quarto-html/quarto.js"></script>
<script src="low_to_moderate_regression_files/libs/quarto-html/popper.min.js"></script>
<script src="low_to_moderate_regression_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="low_to_moderate_regression_files/libs/quarto-html/anchor.min.js"></script>
<link href="low_to_moderate_regression_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="low_to_moderate_regression_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="low_to_moderate_regression_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="low_to_moderate_regression_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="low_to_moderate_regression_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article toc-left">
<div id="quarto-sidebar-toc-left" class="sidebar toc-left">
  <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="99">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a>
  <ul class="collapse">
  <li><a href="#ordinal-logistic-model" id="toc-ordinal-logistic-model" class="nav-link" data-scroll-target="#ordinal-logistic-model">Ordinal Logistic Model</a></li>
  <li><a href="#linear-regression" id="toc-linear-regression" class="nav-link" data-scroll-target="#linear-regression">Linear Regression</a></li>
  <li><a href="#comparing-interpretability-linear-vs.-ordinal" id="toc-comparing-interpretability-linear-vs.-ordinal" class="nav-link" data-scroll-target="#comparing-interpretability-linear-vs.-ordinal">Comparing Interpretability: Linear vs.&nbsp;Ordinal</a></li>
  </ul></li>
  <li><a href="#model-selection" id="toc-model-selection" class="nav-link" data-scroll-target="#model-selection">Model Selection</a>
  <ul class="collapse">
  <li><a href="#removing-variables" id="toc-removing-variables" class="nav-link" data-scroll-target="#removing-variables">Removing Variables</a></li>
  <li><a href="#adding-variables" id="toc-adding-variables" class="nav-link" data-scroll-target="#adding-variables">Adding Variables</a></li>
  </ul></li>
  <li><a href="#model-diagnostics" id="toc-model-diagnostics" class="nav-link" data-scroll-target="#model-diagnostics">Model Diagnostics</a>
  <ul class="collapse">
  <li><a href="#normality-of-errors" id="toc-normality-of-errors" class="nav-link" data-scroll-target="#normality-of-errors">Normality of Errors</a></li>
  <li><a href="#homoskedasticity-of-errors" id="toc-homoskedasticity-of-errors" class="nav-link" data-scroll-target="#homoskedasticity-of-errors">Homoskedasticity of Errors</a></li>
  <li><a href="#outlier-detection" id="toc-outlier-detection" class="nav-link" data-scroll-target="#outlier-detection">Outlier Detection</a></li>
  <li><a href="#linearity" id="toc-linearity" class="nav-link" data-scroll-target="#linearity">Linearity</a></li>
  <li><a href="#additivity" id="toc-additivity" class="nav-link" data-scroll-target="#additivity">Additivity</a></li>
  <li><a href="#no-multicollinearity" id="toc-no-multicollinearity" class="nav-link" data-scroll-target="#no-multicollinearity">No Multicollinearity</a></li>
  <li><a href="#model-calibration" id="toc-model-calibration" class="nav-link" data-scroll-target="#model-calibration">Model Calibration</a></li>
  <li><a href="#final-model-summary" id="toc-final-model-summary" class="nav-link" data-scroll-target="#final-model-summary">Final Model Summary</a></li>
  </ul></li>
  <li><a href="#from-regression-to-classification" id="toc-from-regression-to-classification" class="nav-link" data-scroll-target="#from-regression-to-classification">From Regression to Classification</a>
  <ul class="collapse">
  <li><a href="#classification-performance" id="toc-classification-performance" class="nav-link" data-scroll-target="#classification-performance">Classification Performance</a></li>
  <li><a href="#probabilistic-framing" id="toc-probabilistic-framing" class="nav-link" data-scroll-target="#probabilistic-framing">Probabilistic Framing</a></li>
  </ul></li>
  <li><a href="#interpreting-the-final-model" id="toc-interpreting-the-final-model" class="nav-link" data-scroll-target="#interpreting-the-final-model">Interpreting the Final Model</a>
  <ul class="collapse">
  <li><a href="#predictor-effects" id="toc-predictor-effects" class="nav-link" data-scroll-target="#predictor-effects">Predictor Effects</a></li>
  <li><a href="#simplified-model-comparison" id="toc-simplified-model-comparison" class="nav-link" data-scroll-target="#simplified-model-comparison">Simplified Model Comparison</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul>
</nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Predicting across Low / Moderate Axniety Levels</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Ian McFarlane </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<section id="overview" class="level2">
<h2 class="anchored" data-anchor-id="overview">Overview</h2>
<p>Exploratory plots revealed a strong relationship between Anxiety Level and Stress Level, providing early confidence in predictive modeling. However, before proceeding, we must consider the nature of our outcome variable. Anxiety Level is numerical, but <strong>ordinal</strong>—it has a meaningful order, but not necessarily equal spacing between categories. This complicates model selection, as linear regression assumes a continuous and unbounded outcome, where equal differences between values carry consistent meaning.</p>
<p>We consider two main modeling approaches:</p>
<ul>
<li><p><strong>Linear regression with rounding</strong>, which is easy to interpret but not designed for ordinal data.</p></li>
<li><p><strong>Ordinal logistic regression</strong> <em>(also known as the proportional odds model)</em>, which more accurately reflects the structure of the outcome but is harder to interpret clearly.</p></li>
<li><p>Alternative ordinal modeling frameworks (e.g., partial proportional odds) were not explored, as they were beyond the scope of this analysis.</p></li>
</ul>
<p>Although ordinal logistic regression is more appropriate in theory, its interpretation can be opaque—especially for non-technical audiences. Linear regression, while a simplification, provides direct and intuitive estimates, making it better suited to our goals, which prioritize interpretability and transparency over statistical precision.</p>
<p>That said, we evaluate both models empirically before committing to one. Our first step is to determine which predictors to include. To guide this selection, we use permutation-based variable importance from a random forest model. The resulting plot highlights <code>Stress Level</code> as the most important feature. A noticeable elbow point in the importance scores—specifically between <code>Family History of Anxiety</code> and <code>Occupation</code>—provides a natural cutoff. Based on this, we include the following predictors: <code>Stress Level</code>, <code>Sleep Hours</code>, <code>Caffeine Intake</code>, <code>Therapy Sessions</code>, and <code>Family History of Anxiety</code>.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="low_to_moderate_regression_files/figure-html/feature_importance-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<section id="ordinal-logistic-model" class="level3">
<h3 class="anchored" data-anchor-id="ordinal-logistic-model">Ordinal Logistic Model</h3>
<p>First, we fit the ordinal logistic regression model. The results show a clear pattern: all predictors are directionally consistent with expectations. <code>Stress Level</code>, <code>Caffeine Intake</code>, <code>Therapy Sessions</code>, and <code>Family History of Anxiety</code> are positively associated with higher anxiety levels. In contrast, <code>Sleep Hours</code> has a negative association—more sleep corresponds to lower anxiety.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Call:
polr(formula = ordered(Anxiety.Level) ~ Stress.Level + Sleep.Hours + 
    Caffeine.Intake + Therapy.Sessions + Family.History.of.Anxiety, 
    data = model_data, Hess = TRUE)

Coefficients:
                                 Value Std. Error t value
Stress.Level                  0.608213  0.0085380  71.236
Sleep.Hours                  -0.421707  0.0177904 -23.704
Caffeine.Intake               0.002571  0.0001345  19.119
Therapy.Sessions              0.167046  0.0129053  12.944
Family.History.of.AnxietyYes  0.205308  0.0449721   4.565

Intercepts:
    Value    Std. Error t value 
1|2  -1.6484   0.1351   -12.1995
2|3   0.0611   0.1328     0.4597
3|4   1.7495   0.1345    13.0033
4|5   3.4915   0.1382    25.2554
5|6   5.3197   0.1436    37.0440
6|7   7.3847   0.1664    44.3791

Residual Deviance: 27852.94 
AIC: 27874.94 </code></pre>
</div>
</div>
<p>The confusion matrix below shows that the <strong>model performs modestly</strong> but meaningfully better than chance in predicting anxiety levels. The overall accuracy is 0.383—well above the naïve baseline of approximately 1/7 (~14%) for a seven-class classification task. This performance is consistent with the challenges of modeling subjective human responses, where perfect classification is unlikely due to inherent noise and ambiguity.</p>
<p>Encouragingly, for most predicted classes, <strong>the most common true label is the correct one</strong>, and 86.41% of predictions fall within one level of the actual value. This indicates that while the model may struggle with fine-grained distinctions, it captures the broader structure of the outcome effectively.</p>
<p>One notable limitation is the model’s complete <strong>failure to predict Anxiety Level 7</strong>—the rarest category, with only 123 cases out of 9,986. This likely reflects both <strong>class imbalance</strong> and the ordinal model’s tendency to shrink predictions toward the center of the scale. Potential remedies include reweighting, resampling, or alternative modeling strategies that better account for the tails of the distribution.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction    1    2    3    4    5    6    7
         1  332  205   87   17    1    0    0
         2  484  661  509  154   22    3    0
         3  198  682  995  639  187   22    1
         4   25  193  659 1107  686  158   23
         5    0   15  156  485  681  385   80
         6    0    0    1   14   52   48   19
         7    0    0    0    0    0    0    0

Overall Statistics
                                          
               Accuracy : 0.3829          
                 95% CI : (0.3734, 0.3926)
    No Information Rate : 0.2419          
    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
                                          
                  Kappa : 0.2247          
                                          
 Mcnemar's Test P-Value : NA              </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Proportion of cases predicted within one level of the true level 0.8641</code></pre>
</div>
</div>
<section id="lightweight-diagnostics" class="level4">
<h4 class="anchored" data-anchor-id="lightweight-diagnostics">Lightweight Diagnostics</h4>
<p>We formally tested the proportional odds assumption using the Brant test. The omnibus test was significant, indicating that the assumption does not hold strictly. At the individual level, Stress Level, Sleep Hours, and Caffeine Intake also showed statistically significant violations.</p>
<p>However, visual inspection of the empirical cumulative logits for each predictor revealed near-parallel trends across thresholds, broadly consistent with the proportional odds framework. A slight divergence in slope between the <code>Anxiety ≥ 2</code> and <code>Anxiety ≥ 3</code> thresholds is visible—particularly for Stress Level—suggesting mild non-proportionality at the lower end of the anxiety scale. Additionally, the slope for <code>Anxiety ≥ 7</code> behaves somewhat erratically, likely due to extreme class imbalance at the highest anxiety level.</p>
<p>Taken together, these results suggest that while the proportional odds assumption is not strictly met, the observed deviations appear minor and not practically consequential. An ordinal logistic model, while not ideal for interpretability, remains an adequate modeling choice for capturing the relationship between predictors and ordinal anxiety levels.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>------------------------------------------------------------ 
Test for            X2  df  probability 
------------------------------------------------------------ 
Omnibus             50.1    25  0
Stress.Level            14.11   5   0.01
Sleep.Hours         9.71    5   0.08
Caffeine.Intake     17.07   5   0
Therapy.Sessions        1.77    5   0.88
Family.History.of.AnxietyYes    4.26    5   0.51
------------------------------------------------------------ 

H0: Parallel Regression Assumption holds</code></pre>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="low_to_moderate_regression_files/figure-html/parallel_slopes_plot-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="1344"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="linear-regression" class="level3">
<h3 class="anchored" data-anchor-id="linear-regression">Linear Regression</h3>
<p>We next examine the linear regression model. Its results closely mirror those of the ordinal model: <code>Sleep Hours</code> shows a negative association with <code>Anxiety Level</code>, while <code>Stress Level</code>, <code>Caffeine Intake</code>, <code>Therapy Sessions</code>, and <code>Family History of Anxiety</code> all exhibit positive associations. The model’s <span class="math inline">\(R^2\)</span> of 0.519 suggests moderate predictive power—consistent with the classification accuracy observed earlier. This alignment indicates that, despite its misspecification, the linear regression model effectively captures the main structure of the data.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = Anxiety.Level ~ Stress.Level + Sleep.Hours + Caffeine.Intake + 
    Therapy.Sessions + Family.History.of.Anxiety, data = model_data)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.4311 -0.7081 -0.0281  0.6776  3.6825 

Coefficients:
                               Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)                   2.503e+00  7.171e-02  34.899  &lt; 2e-16 ***
Stress.Level                  3.385e-01  3.476e-03  97.379  &lt; 2e-16 ***
Sleep.Hours                  -2.296e-01  9.412e-03 -24.399  &lt; 2e-16 ***
Caffeine.Intake               1.399e-03  7.171e-05  19.502  &lt; 2e-16 ***
Therapy.Sessions              9.145e-02  6.957e-03  13.145  &lt; 2e-16 ***
Family.History.of.AnxietyYes  1.156e-01  2.437e-02   4.743 2.14e-06 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.9962 on 9980 degrees of freedom
Multiple R-squared:  0.5194,    Adjusted R-squared:  0.5191 
F-statistic:  2157 on 5 and 9980 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>The confusion matrix below also tells a similar story. The linear regression model achieves an accuracy of 0.376, closely matching the ordinal model. Once again, the most frequent prediction for each true level is typically the correct one, no observations are predicted as an Anxiety Level of 7, and 87.27% of predictions fall within one level of the true value. Taken together, these results suggest that both models perform comparably.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction    1    2    3    4    5    6    7
         1  105   52   14    4    0    0    0
         2  687  755  520  146   15    3    0
         3  222  749 1070  687  202   23    1
         4   25  189  672 1133  725  169   27
         5    0   11  131  437  657  384   80
         6    0    0    0    9   30   37   15
         7    0    0    0    0    0    0    0

Overall Statistics
                                          
               Accuracy : 0.3762          
                 95% CI : (0.3667, 0.3858)
    No Information Rate : 0.2419          
    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
                                          
                  Kappa : 0.2103          
                                          
 Mcnemar's Test P-Value : NA              </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Cases predicted within one level of the true level: 87.27%</code></pre>
</div>
</div>
<p>However, where the linear regression model differs most from the ordinal logistic model is in its <strong>treatment of the extremes</strong>. The linear regression model severely <strong>underpredicts Classes 1 and 6</strong>. For instance, among cases truly labeled as 1, more are predicted as 3 than as 1; for true sixes, the model more frequently predicts a 4 than a 6. This reflects a well-known property of linear regression: a tendency to regress toward the mean.</p>
<p>While alternative approaches such as weighted regression can reduce this issue, they do so by distorting the underlying data distribution or sacrificing interpretability—both of which conflict with our modeling goals. The ordinal logistic model also exhibits this bias, but to a lesser extent, owing to its structure that better respects ordinal spacing.</p>
</section>
<section id="comparing-interpretability-linear-vs.-ordinal" class="level3">
<h3 class="anchored" data-anchor-id="comparing-interpretability-linear-vs.-ordinal">Comparing Interpretability: Linear vs.&nbsp;Ordinal</h3>
<p>Although the ordinal logistic model is statistically well-suited to ordered outcomes, its coefficients are often harder to interpret in practical terms. For example, the model estimates that:</p>
<blockquote class="blockquote">
<p>Each additional hour of sleep reduces the log-odds of reporting a higher anxiety level by 0.52.</p>
</blockquote>
<p>While this may be meaningful to a statistician, log-odds are abstract and unintuitive for most readers. Even when translated into odds ratios—about a 40% reduction in the odds of being in a higher anxiety category—the interpretation remains ambiguous. What does “higher category” mean in practice? And how much higher?</p>
<p>Moreover, the phrase “reporting a higher anxiety level” is conceptually fuzzy for those unfamiliar with ordinal logistic regression—it doesn’t map cleanly onto expected values or real-number outcomes.</p>
<p>By contrast, the linear model produces a more direct and accessible statement:</p>
<blockquote class="blockquote">
<p>Each additional hour of sleep is associated with a 0.23-point decrease in expected anxiety level.</p>
</blockquote>
<p>This clear mapping from input units to outcome makes the results more tangible—especially for non-technical audiences. The ability to express predictor effects in everyday terms was a key reason for ultimately <strong>favoring the linear model in this analysis, despite its formal misspecification</strong> and its limited reliability at the edges of the scale. As we’ll explore later, the predictions themselves are inherently fuzzy, further supporting our emphasis on interpretability over classification precision. In addition, by modeling high-anxiety individuals (levels 8–10) separately, we avoid the primary predictive risk—misclassifying the people most in need of identification—and allow the linear model to focus on the more stable patterns within the moderate anxiety range.</p>
</section>
</section>
<section id="model-selection" class="level2">
<h2 class="anchored" data-anchor-id="model-selection">Model Selection</h2>
<p>Now that we’ve selected <strong>linear regression</strong> as our preferred model—prioritizing parsimony and interpretability—we begin with a baseline that includes <code>Stress Level</code>, <code>Sleep Hours</code>, <code>Caffeine Intake</code>, <code>Therapy Sessions</code>, and <code>Family History of Anxiety</code>, based on prior feature importance analysis.</p>
<p>Next, we assess whether any of these variables should be removed or if others should be added.</p>
<section id="removing-variables" class="level3">
<h3 class="anchored" data-anchor-id="removing-variables">Removing Variables</h3>
<p>To evaluate whether each predictor meaningfully contributes to the model, we compare BIC and Bayes Factor values after individually dropping each one.</p>
<p>The results below suggest that <code>Stress Level</code> is indispensable (as expected), with a BIC increase of nearly 7,000 when removed. <code>Sleep Hours</code>, <code>Caffeine Intake</code>, and <code>Therapy Sessions</code> also show strong support for inclusion based on substantial BIC increases and Bayes Factors.</p>
<p><code>Family History of Anxiety</code> presents weaker evidence, but the change is still large enough to justify its retention under the principle of parsimony—each variable adds unique explanatory value without unnecessarily inflating model complexity.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Stress Level:</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                      aic      bic bayes.factor      p   rsq adj.rsq
simplified_model 34938.68 34981.93            0 &lt;2e-16 0.063   0.062
linear_model     28270.88 28321.34          Inf        0.519   0.519</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Sleep Hours:</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                      aic      bic  bayes.factor      p   rsq adj.rsq
simplified_model 28847.44 28890.69  0.000000e+00 &lt;2e-16 0.491   0.490
linear_model     28270.88 28321.34 4.293248e+123        0.519   0.519</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Caffeine Intake:</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                      aic      bic bayes.factor      p   rsq adj.rsq
simplified_model 28642.38 28685.64 0.000000e+00 &lt;2e-16 0.501   0.501
linear_model     28270.88 28321.34 1.274688e+79        0.519   0.519</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Therapy Sessions:</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                      aic      bic bayes.factor      p   rsq adj.rsq
simplified_model 28440.29 28483.54 0.000000e+00 &lt;2e-16 0.511   0.511
linear_model     28270.88 28321.34 1.665933e+35        0.519   0.519</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Family History of Anxiety:</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                      aic      bic bayes.factor      p   rsq adj.rsq
simplified_model 28291.36 28334.62        0.001 &lt;2e-16 0.518   0.518
linear_model     28270.88 28321.34      762.941        0.519   0.519</code></pre>
</div>
</div>
</section>
<section id="adding-variables" class="level3">
<h3 class="anchored" data-anchor-id="adding-variables">Adding Variables</h3>
<p>To test whether the model could benefit from an additional predictor, we examine the next-highest ranked variable from the feature importance analysis: Occupation.</p>
<p>Adding Occupation results in a higher BIC and a Bayes Factor favoring the original model, indicating that its inclusion does not improve model fit enough to justify the added complexity. This supports our earlier decision to treat Occupation as beyond the importance elbow point.</p>
<p>Given this result, we retain the original model as our final specification for this analysis.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>                      aic      bic bayes.factor     p   rsq adj.rsq
linear_model     28270.88 28321.34 4.912824e+21 0.563 0.519   0.519
occupation_added 28284.27 28421.24 0.000000e+00       0.520   0.519</code></pre>
</div>
</div>
</section>
</section>
<section id="model-diagnostics" class="level2">
<h2 class="anchored" data-anchor-id="model-diagnostics">Model Diagnostics</h2>
<p>With our model selected, we now assess its diagnostics to ensure the assumptions of linear regression are reasonably satisfied and that the results are stable and interpretable. This section is organized around four diagnostic pillars:</p>
<ul>
<li><strong>Error distribution checks</strong>, including assessments of normality and homoskedasticity. While formal inference is not our focus, these checks help us understand residual behavior and identify potential misspecification.</li>
<li><strong>Outlier analysis</strong>, which helps detect individual observations with high influence or poor fit that may distort coefficient estimates.</li>
<li><strong>Structural assumption checks</strong>, covering linearity, additivity (no interaction terms), and multicollinearity, to confirm that the model’s functional form is appropriate for the data.</li>
<li><strong>Calibration assessment</strong>, which ensures that predicted values align with observed responses and reflect meaningful expected outcomes.</li>
</ul>
<section id="normality-of-errors" class="level3">
<h3 class="anchored" data-anchor-id="normality-of-errors">Normality of Errors</h3>
<p>The Q-Q plot shows slight “S-bending” near the tails, indicating mild deviations from perfect normality—likely due to applying linear regression to a bounded ordinal outcome. However, the residuals remain approximately symmetric, with no significant skewness or heavy tails.</p>
<div class="cell">
<div class="cell-output cell-output-stderr">
<pre><code>Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.
ℹ Please use `after_stat(density)` instead.</code></pre>
</div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="low_to_moderate_regression_files/figure-html/error_normality-1.png" class="img-fluid figure-img" width="1344"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="homoskedasticity-of-errors" class="level3">
<h3 class="anchored" data-anchor-id="homoskedasticity-of-errors">Homoskedasticity of Errors</h3>
<p>Due to the discrete and bounded nature of the outcome, the residual plot displays clear banding patterns—an expected artifact of applying linear regression to ordinal data. Nevertheless, the LOESS smoother remains essentially flat, indicating no substantial heteroskedasticity.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output cell-output-stderr">
<pre><code>`geom_smooth()` using formula = 'y ~ x'</code></pre>
</div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="low_to_moderate_regression_files/figure-html/error_homoskedasticity-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="outlier-detection" class="level3">
<h3 class="anchored" data-anchor-id="outlier-detection">Outlier Detection</h3>
<p>To explore this possibility, we’re using the same plots as in the logistic model (with the appropriate changes)</p>
<p>The four plots include:</p>
<ol type="1">
<li><p>Leverage vs.&nbsp;Cook’s Distance</p></li>
<li><p>Predicted Anxiety vs.&nbsp;Studentized Residuals</p></li>
<li><p>Leverage vs.&nbsp;Studentized Residuals</p></li>
<li><p>Cook’s Distance by Observation Index</p></li>
</ol>
<div>

</div>
<div class="cell quarto-layout-panel" data-layout-nrow="2" data-layout-align="center">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 100.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="low_to_moderate_regression_files/figure-html/outlier_plots-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="1344"></p>
</figure>
</div>
</div>
</div>
</div>
<p>Most observations appear well behaved, with no evidence of influential outliers. Cook’s distances are uniformly low (maximum &lt; 0.003), indicating no individual point exerts undue influence on the model’s estimates. A small number of observations exceed the ±3 threshold for studentized residuals, which is expected in a dataset of this size. These high-residual points generally have low leverage and do not coincide with extreme influence measures.</p>
<p>The absence of high-leverage, high-residual combinations, combined with the overall stability of influence metrics, suggests that the model is not disproportionately shaped by any small subset of observations. While residual banding is present due to the ordinal nature of the outcome, it does not raise concern about outlier-driven distortion.</p>
<p>A few observations did exhibit either larger residuals or higher-than-average leverage, but none met criteria for being both poorly predicted and highly influential. These points were retained, as they are consistent with the expected variability in the data and do not materially affect model fit.</p>
</section>
<section id="linearity" class="level3">
<h3 class="anchored" data-anchor-id="linearity">Linearity</h3>
<p>Since linearity concerns only numerical predictors, there is no need to assess this assumption for categorical variables such as Family History of Anxiety. For the remaining continuous predictors, plots of each variable against predicted anxiety show strong linear trends. Although slight deviations appear in the tails—particularly at extreme values—these are minor and do not suggest meaningful nonlinearity.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="low_to_moderate_regression_files/figure-html/linearity-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="1344"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="additivity" class="level3">
<h3 class="anchored" data-anchor-id="additivity">Additivity</h3>
<p>A likelihood ratio test showed no evidence that including interaction terms improves model fit (p = 0.84), suggesting that additivity is a reasonable working assumption for this analysis. While interactions could exist, their effects appear negligible in this context.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Variance Table

Model 1: Anxiety.Level ~ Stress.Level + Sleep.Hours + Caffeine.Intake + 
    Therapy.Sessions + Family.History.of.Anxiety
Model 2: Anxiety.Level ~ (Stress.Level + Sleep.Hours + Caffeine.Intake + 
    Therapy.Sessions + Family.History.of.Anxiety)^2
  Res.Df    RSS Df Sum of Sq Pr(&gt;Chi)
1   9980 9904.2                      
2   9970 9898.5 10    5.6562     0.84</code></pre>
</div>
</div>
</section>
<section id="no-multicollinearity" class="level3">
<h3 class="anchored" data-anchor-id="no-multicollinearity">No Multicollinearity</h3>
<p>All predictors in the model have variance inflation factors (VIFs) below 1.5—well below the commonly used threshold of 5. This suggests that multicollinearity is not a concern and that the predictors are sufficiently independent to yield stable, interpretable coefficients.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Variance Inflation Factors:</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>             Stress.Level               Sleep.Hours           Caffeine.Intake 
                 1.000231                  1.001329                  1.000781 
         Therapy.Sessions Family.History.of.Anxiety 
                 1.493893                  1.493447 </code></pre>
</div>
</div>
</section>
<section id="model-calibration" class="level3">
<h3 class="anchored" data-anchor-id="model-calibration">Model Calibration</h3>
<p>Because our goal is interpretation, it’s essential to verify that the model’s predicted values are meaningful representations of expected outcomes. A predicted Anxiety Level of 5.4, while not an actual possible score, reflects the <strong>expected value</strong> for someone with those characteristics. For the predicted values to be interpretable, the model must be <strong>well-calibrated</strong>—that is, predictions should closely align with the average observed outcomes.</p>
<p>To assess calibration, we compared the model’s predictions to the actual mean Anxiety Levels within quantile-based bins of predicted values. The resulting calibration plot shows a near-perfect alignment along the identity line, suggesting that the model’s predictions closely approximate average observed outcomes across the range of predicted values. This supports the claim that the linear regression model provides reliable and interpretable estimates across the full range of predictions</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="low_to_moderate_regression_files/figure-html/calibration_plot-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="final-model-summary" class="level3">
<h3 class="anchored" data-anchor-id="final-model-summary">Final Model Summary</h3>
<p>Despite the model’s intentional misspecification—applying linear regression to a bounded ordinal outcome—diagnostics suggest that all key assumptions are reasonably satisfied. Residuals are approximately normal and homoskedastic. No influential outliers are present, and both linearity and additivity hold for the numeric predictors. Multicollinearity is negligible.. Taken together, these results indicate that the model is stable and interpretable, and that the tradeoff in favor of simplicity has not compromised its validity for exploratory or communicative purposes.</p>
</section>
</section>
<section id="from-regression-to-classification" class="level2">
<h2 class="anchored" data-anchor-id="from-regression-to-classification">From Regression to Classification</h2>
<p>To convert the linear regression model’s continuous predictions into discrete classes, we apply simple rounding. While this may reduce predictive precision, it avoids the added complexity of optimizing thresholds—especially since such methods often bias results toward the majority class in boundary regions.</p>
<section id="classification-performance" class="level3">
<h3 class="anchored" data-anchor-id="classification-performance">Classification Performance</h3>
<p>Although we previously reviewed classification performance in the overview section, we briefly revisit the results here for context.</p>
<blockquote class="blockquote">
<p>The linear regression model achieves an accuracy of 0.376, closely matching the ordinal model. Once again, the most frequent prediction for each true level is typically the correct one, no observations are predicted as an Anxiety Level of 7, and 87.27% of predictions fall within one level of the true value.</p>
</blockquote>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction    1    2    3    4    5    6    7
         1  105   52   14    4    0    0    0
         2  687  755  520  146   15    3    0
         3  222  749 1070  687  202   23    1
         4   25  189  672 1133  725  169   27
         5    0   11  131  437  657  384   80
         6    0    0    0    9   30   37   15
         7    0    0    0    0    0    0    0

Overall Statistics
                                          
               Accuracy : 0.3762          
                 95% CI : (0.3667, 0.3858)
    No Information Rate : 0.2419          
    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
                                          
                  Kappa : 0.2103          
                                          
 Mcnemar's Test P-Value : NA              </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Proportion of cases predicted within one level of the true level 0.8727</code></pre>
</div>
</div>
<p>Now that we’ve revisited the results, let’s take a closer look at the <strong>within-one accuracy</strong> metric. At first glance, this may seem like an overly generous statistic. However, it’s important to recognize that <strong>humans tend to struggle to reliably distinguish between adjacent levels on fine-grained ordinal scales</strong>—especially when the number of levels exceeds 7.</p>
<blockquote class="blockquote">
<p>“Humans have difficulty reliably distinguishing between more than 5 to 7 categories on a rating scale, with reliability and interpretability decreasing as the number of levels increases.” — Miller, G. A. (1956). <em>“The Magical Number Seven, Plus or Minus Two: Some Limits on Our Capacity for Processing Information.” Psychological Review, 63</em>(2), 81–97.</p>
</blockquote>
<p>Although our model is trained on a 1–7 scale, the original data was recorded on a 1–10 scale, likely introducing <strong>subjective noise</strong> and <strong>imprecision</strong> in how respondents rated themselves. In this context, a within-one accuracy of 87% better captures the model’s practical performance than strict classification accuracy.</p>
<p>That said, this metric is indeed optimistic, and we acknowledge its limitations. Still, given the inherent ambiguity in human-rated scales, within-one accuracy offers a more forgiving and arguably more realistic view of model effectiveness.</p>
</section>
<section id="probabilistic-framing" class="level3">
<h3 class="anchored" data-anchor-id="probabilistic-framing">Probabilistic Framing</h3>
<p>Moreover, from the diagnostics we know that the errors roughly follow a normal distribution. Actually, they roughly follow a standard normal distribution, which gives us the following insights:</p>
<ul>
<li><p><strong>Residuals within ±0.5</strong> (i.e., correct prediction after rounding): 37.62%</p></li>
<li><p><strong>Residuals within ±1.0</strong> (empirical rule ≈ 68%): 67.31%</p></li>
<li><p><strong>Residuals within ±1.5 (within-one threshold for classification):</strong> 87.27%</p></li>
<li><p><strong>Residuals within ±2.0 (empirical rule ≈ 95%):</strong> 95.79%</p></li>
</ul>
<div class="cell" data-layout-align="center">
<div class="cell-output cell-output-stderr">
<pre><code>Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.
ℹ Please use `linewidth` instead.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in annotate("text", x = 0.55, y = 600, label = "±0.5 (Correct
Prediction)", : Ignoring unknown parameters: `linewidth`</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in annotate("text", x = 1.55, y = 550, label = "±1.5 (Within-One
Prediction)", : Ignoring unknown parameters: `linewidth`</code></pre>
</div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="low_to_moderate_regression_files/figure-html/normal_residuals-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
</div>
</div>
<p>The residuals from the linear regression model approximate a normal distribution, which supports our use of the Gaussian framework to describe prediction uncertainty. That said, this behavior reflects both the underlying signal and the constraints of modeling a bounded ordinal outcome with a continuous method. In particular, residuals near the edges of the anxiety scale (1 and 7) are limited by ceiling and floor effects, which may distort the distribution’s tails.</p>
<p>For this reason, the normal approximation should be seen as a useful simplification rather than a strict assumption. It allows us to frame uncertainty in relatable terms (e.g., “usually within ±1”), while recognizing that such interpretations are approximate. In this exploratory context, we find that this framing aids communication without meaningfully distorting the model’s behavior.</p>
</section>
</section>
<section id="interpreting-the-final-model" class="level2">
<h2 class="anchored" data-anchor-id="interpreting-the-final-model">Interpreting the Final Model</h2>
<section id="predictor-effects" class="level3">
<h3 class="anchored" data-anchor-id="predictor-effects">Predictor Effects</h3>
<p>Now that we’re confident in the quality of our model, let’s take a closer look at the regression equation:</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = Anxiety.Level ~ Stress.Level + Sleep.Hours + Caffeine.Intake + 
    Therapy.Sessions + Family.History.of.Anxiety, data = model_data)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.4311 -0.7081 -0.0281  0.6776  3.6825 

Coefficients:
                               Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)                   2.503e+00  7.171e-02  34.899  &lt; 2e-16 ***
Stress.Level                  3.385e-01  3.476e-03  97.379  &lt; 2e-16 ***
Sleep.Hours                  -2.296e-01  9.412e-03 -24.399  &lt; 2e-16 ***
Caffeine.Intake               1.399e-03  7.171e-05  19.502  &lt; 2e-16 ***
Therapy.Sessions              9.145e-02  6.957e-03  13.145  &lt; 2e-16 ***
Family.History.of.AnxietyYes  1.156e-01  2.437e-02   4.743 2.14e-06 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.9962 on 9980 degrees of freedom
Multiple R-squared:  0.5194,    Adjusted R-squared:  0.5191 
F-statistic:  2157 on 5 and 9980 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p><span class="math display">\[
\begin{align*}
\widehat{\text{Anxiety Level}} =\ &amp; 2.503 \\
&amp;+ 0.339\ \cdot\ \text{Stress Level} \\
&amp;- 0.230\ \cdot\ \text{Sleep Hours} \\
&amp;+ 0.00140\ \cdot\ \text{Caffeine Intake} \\
&amp;+ 0.0915\ \cdot\ \text{Therapy Sessions} \\
&amp;+ 0.116\ \cdot\ \text{Family History of Anxiety}_{\text{Yes}}
\end{align*}
\]</span></p>
<p>The accompanying interpretations are as follows:</p>
<ul>
<li><p>Each additional Stress Level increases the expected Anxiety Level by 0.339, holding all other variables constant.</p></li>
<li><p>Each additional hour of Sleep decreases the expected Anxiety Level by 0.230, holding all other variables constant.</p></li>
<li><p>Each additional Therapy Session increases the expected Anxiety Level by 0.0915, holding all other variables constant.</p></li>
<li><p>Each additional milligram of Caffeine increases the expected Anxiety Level by 0.00140, holding all other variables constant. In practical terms, an additional cup of coffee (≈100 mg) increases the expected Anxiety Level by 0.140.</p></li>
<li><p>Individuals with a Family History of Anxiety predicted to score 0.116 points higher on the Anxiety Level scale than those without, controlling for the other variables.</p></li>
</ul>
<p>While the scale of the traditional interpretation doesn’t yield a straightforward one-to-one correspondence between predictors and Anxiety Levels, it still offers valuable insight: anxiety is multifaceted, and no single variable fully explains it.</p>
<ul>
<li><p>When we increased Stress Level by 3 units, while holding all else constant, the predicted Anxiety Level increased by about 1 point. Similarly, increasing Sleep Hours by 4 led to roughly a 1-point decrease in predicted Anxiety. These align closely with the effect sizes in the model and illustrate the trade-offs.</p></li>
<li><p>In contrast, it would take about 10 additional therapy sessions or the equivalent of 7 extra cups of coffee to shift the predicted Anxiety Level by just 1 point. This confirms that while statistically significant, these variables have relatively modest effects in practical terms.</p></li>
<li><p>As for Family History of Anxiety, the model predicts a small increase—just over a tenth of a point. However, in cases where someone’s predicted anxiety is right on the edge between two categories, this small nudge can be enough to shift the prediction from one level to the next. So, while not a strong driver on its own, it may still influence certain borderline predictions.</p></li>
</ul>
<p>This, however, does not mean that variables like Therapy Sessions, Caffeine Intake, and Family History are irrelevant to prediction—only that their individual effects on Anxiety Level are modest.</p>
</section>
<section id="simplified-model-comparison" class="level3">
<h3 class="anchored" data-anchor-id="simplified-model-comparison">Simplified Model Comparison</h3>
<p>To assess the contribution of lower-impact variables, we fit a simplified linear model using only <code>Stress Level</code> and <code>Sleep Hours</code>. While this model maintained comparable overall accuracy (35.7%) and within-one accuracy (85.5%), it struggled even more at the extremes—particularly for Classes 1 and 6—further emphasizing the linear model’s tendency to regress toward the mean. This comparison reinforces that even modest predictors can improve edge-case performance and stabilize the model’s behavior, supporting their inclusion.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = Anxiety.Level ~ Stress.Level + Sleep.Hours, data = model_data)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.6466 -0.7463 -0.0211  0.7093  3.8968 

Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)   3.119006   0.070439   44.28   &lt;2e-16 ***
Stress.Level  0.338262   0.003609   93.72   &lt;2e-16 ***
Sleep.Hours  -0.229016   0.009769  -23.44   &lt;2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.034 on 9983 degrees of freedom
Multiple R-squared:  0.4815,    Adjusted R-squared:  0.4814 
F-statistic:  4636 on 2 and 9983 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction    1    2    3    4    5    6    7
         1   36   12    5    1    0    0    0
         2  712  769  527  155   19    3    0
         3  261  751 1049  722  229   25    3
         4   29  209  660 1080  728  208   36
         5    1   15  165  457  645  377   84
         6    0    0    1    1    8    3    0
         7    0    0    0    0    0    0    0

Overall Statistics
                                          
               Accuracy : 0.3587          
                 95% CI : (0.3493, 0.3682)
    No Information Rate : 0.2419          
    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
                                          
                  Kappa : 0.1857          
                                          
 Mcnemar's Test P-Value : NA              </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Proportion of cases predicted within one level of the true level 0.8548</code></pre>
</div>
</div>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>In modeling moderate anxiety levels (1–7), we evaluated both ordinal logistic regression and linear regression. While the ordinal approach more closely matches the structure of the outcome variable, it posed interpretive challenges and did not offer meaningful improvements in predictive performance. The linear model, despite its formal misspecification, produced comparable accuracy, more transparent diagnostics, and a direct mapping from predictors to expected values—making it the more appropriate choice given the goals of this analysis.</p>
<p>The final model revealed consistent and intuitive relationships: higher stress, greater caffeine intake, more therapy sessions, and a family history of anxiety were all associated with increased anxiety levels, while more sleep was linked to lower levels. Although the individual effects were modest, together they provided a stable and interpretable picture of the factors most associated with anxiety in this dataset. Diagnostic checks supported the model’s overall validity: residuals were well-behaved, multicollinearity was negligible, and most predictions fell within one level of the true anxiety score.</p>
<p>While the linear model underpredicts at the extremes—particularly for rare or low-frequency anxiety levels—this limitation is expected given the bounded, subjective nature of the response variable. A strictly ordinal logistic model, while more theoretically appropriate, would have constrained our ability to inspect residual behavior and model calibration in the same interpretable way. Ultimately, the linear regression model strikes a practical balance between statistical structure and communicative clarity.</p>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>